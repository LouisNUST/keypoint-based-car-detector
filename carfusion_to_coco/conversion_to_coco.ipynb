{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def num(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return int(float(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to process the carfusion dataset to make it readable by openpifpaf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keypoints will be processed in a COCO formatting and a car detection with ImageAi will be performed to detect the cars without bounding box. In fact, the carfusion dataset only provides a list of keypoints and no information about the other non annotated cars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the ImageAi detection on the images, we determine an IOU to applicate on the images in order to annotate only the cars without keypoints (default = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageAi \n",
    "The objective is to detect the cars which are not annotated. This way, we will be able to create a bounding box for the cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bonnesoe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings of the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bonnesoe/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"./model/yolo.h5\") #link of the yolo model for car detection\n",
    "# You can download it here : https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detector is configured to detect only cars, bus and trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU = 0.3\n",
    "car_only = False                     #Yolov3 detects the cars, buses and van, by puting car_only to True, it will only detect the cars\n",
    "dir_carfusion=\"./datasets/carfusion\" #Directory of carfusion\n",
    "number_keypoints = 14 #Number of keypoint for the cars "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to remove some keypoints in the carfusion dataset, you can use the span0 and span1 variables which will remove the keypoints in the interval :  ]span0, span1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Used to remove a set of keypoints in the interval ]span0, span1]\n",
    "span0 = span1 = 0\n",
    "#span0 = 8\n",
    "#span1 = 10\n",
    "\n",
    "text = str(IOU)\n",
    "\n",
    "if span0 != span1:\n",
    "    text+=\"_\"+str(span0)+\"_\"+str(span1)\n",
    "\n",
    "keypoints_threshold = 1 # minimum number of keypoints to consider the cars in both the training and validation dataset\n",
    "\n",
    "\n",
    "out = \"./1.jpg\" # choose whatever name/place that you want (only used during processing, nothing is saved)\n",
    "\n",
    "if car_only:\n",
    "    custom = detector.CustomObjects(car=True, truck=False, bus=False)\n",
    "else: \n",
    "    custom = detector.CustomObjects(car=True, truck=True, bus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton =[\n",
    "            [1, 2], [1,3], [2,4], [3,4],    #wheels\n",
    "            [1,5], [2,6],[3,7], [4,8],      #Links between the wheels and the lights\n",
    "            #[5,6], [7,8],                   #links between the lights\n",
    "            [5,9], [6,10],                  #links between the mirrors and the front lights\n",
    "            [5,11],[6,12], [7,13],[8,14],   #links between the lights and the windshiel/rear\n",
    "            [11,12],[11,13],[12,14],[13,14] #links between the rear and the windshiel ,\n",
    "            ]\n",
    "    \n",
    "    \n",
    "COCO_KEYPOINTS = [\n",
    "    'front_left_wheel',         #1          0\n",
    "    'front_right_wheel',        #2          1\n",
    "    'back_left_wheel',          #3          2\n",
    "    'back_right_wheel',         #4          3\n",
    "    'front_left_light',         #5          4\n",
    "    'front_right_light',        #6          5\n",
    "    'back_left_light',          #7          6\n",
    "    'back_right_light',         #8          7\n",
    "    'left_mirror',              #9          8\n",
    "    'right_mirror',             #10         9\n",
    "    'upper_left_windshield',    #11         10\n",
    "    'upper_right_windshield',   #12         11\n",
    "    'upper_left_rear',          #13         12\n",
    "    'upper_right_rear',         #14         13\n",
    "]\n",
    "\n",
    "reorder_keypoints = [1,0,3,2,5,4,7,6,13,8,10,9,12,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnnotation(instance, total_keypoints ,width, height):\n",
    "\n",
    "    valid_2 = instance[:, 2] == 1\n",
    "    valid = instance[:, 2] == 2\n",
    "\n",
    "    visible = np.logical_or(valid, valid_2)\n",
    "    num_keypoints = int(np.sum(visible))\n",
    "\n",
    "    keypoints = np.zeros((total_keypoints,3), dtype=np.int32)\n",
    "    try:\n",
    "        hull = Polygon([(x[0], x[1]) for x in instance[visible, :2]]).convex_hull\n",
    "        frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "        hull = hull.intersection(frame).convex_hull\n",
    "\n",
    "        bbox = hull.bounds\n",
    "        w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "        x_o = max(bbox[0]-(w/10),0)\n",
    "        y_o = max(bbox[1]-(h/10),0)\n",
    "        x_i = min(x_o+(w/4)+w,width)\n",
    "        y_i = min(y_o+(h/4)+h,height)\n",
    "        bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "\n",
    "        segmentation = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "        segmentation = [[int(x[0]), int(x[1])] for x in segmentation]\n",
    "\n",
    "        keypoints[:, :] = instance[:, :]\n",
    "\n",
    "    except:\n",
    "        bbox = [0, 0, 0, 0]\n",
    "        segmentation = []\n",
    "\n",
    "    keypoints = keypoints[reorder_keypoints,:]\n",
    "    #print(keypoints.shape)\n",
    "    keypoints = np.reshape(keypoints, (total_keypoints*3,))\n",
    "    keypoints = keypoints.tolist()\n",
    "    keypoints = [int(x) for x in keypoints]\n",
    "    \n",
    "    #print(keypoints)\n",
    "\n",
    "    seg = []\n",
    "    for s in segmentation:\n",
    "        seg.append(s[0])\n",
    "        seg.append(s[1])\n",
    "\n",
    "\n",
    "    return bbox, seg, keypoints, num_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IOU(boxA, boxB):\n",
    "\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0]+boxA[2], boxB[0]+boxB[2])\n",
    "    yB = min(boxA[1]+boxA[3], boxB[1]+ boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = boxA[2]*boxA[3]\n",
    "    boxBArea = boxB[2]*boxB[3]\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return abs(iou)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of our data structure and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type='test'\n",
    "\n",
    "iou_threshold = IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if car_only:\n",
    "    output_filename = 'car_only_'+ data_type+text\n",
    "else:\n",
    "    output_filename = 'car_'+ data_type+text\n",
    "\n",
    "if data_type=='train':\n",
    "    image_dir = os.path.join(dir_carfusion,\"train\")\n",
    "else:\n",
    "    image_dir = os.path.join(dir_carfusion,\"test\")\n",
    "    \n",
    "output_dir = os.getcwd()+\"/annotations\"\n",
    "path_dir = dir_carfusion\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "data[\"info\"] = {\n",
    "        'url': \"https://www.epfl.ch/labs/vita/\",\n",
    "        'year': time.localtime().tm_year,\n",
    "        'date_created': time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\",\n",
    "            time.localtime()),\n",
    "        'description': \"This is a keypoint dataset for object detection.\",\n",
    "        'version': '1.0',\n",
    "        'contributor': 'VITA laboratory'}\n",
    "\n",
    "data[\"categories\"] = [{'name': 'car',\n",
    "    'id': 1,\n",
    "    'skeleton':skeleton,\n",
    "                       \n",
    "    'supercategory': 'car',\n",
    "    'keypoints': [str(x) for x in range(14)]}]\n",
    "\n",
    "data[\"licenses\"] = [{'id': 1,\n",
    "            'name': \"unknown\",\n",
    "            'url': \"unknown\"}]\n",
    "\n",
    "\n",
    "obj_id = 0\n",
    "# expect sub-folder for subsets\n",
    "data[\"images\"] = []\n",
    "data[\"annotations\"] = []\n",
    "json_name = output_filename+'.json'\n",
    "loop=0\n",
    "count_images=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/carfusion/test/car_penn1/images_jpg\n",
      "there is 0 images processed on the 6919 available.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Ensure you specified correct input image, input type, output type and/or output image path ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/imageai/Detection/__init__.py\u001b[0m in \u001b[0;36mdetectCustomObjectsFromImage\u001b[0;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[1;32m    835\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__yolo_input_image_shape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m                             })\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-486b02f582bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#detect the cars in the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectCustomObjectsFromImage\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_percentage_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mboxes_imageAI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/imageai/Detection/__init__.py\u001b[0m in \u001b[0;36mdetectCustomObjectsFromImage\u001b[0;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 919\u001b[0;31m                     \"Ensure you specified correct input image, input type, output type and/or output image path \")\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Ensure you specified correct input image, input type, output type and/or output image path "
     ]
    }
   ],
   "source": [
    "for sub_dir in os.listdir(image_dir):\n",
    "    im_size = True\n",
    "    \n",
    "    if sub_dir[:3] == 'car' and \".zip\" not in sub_dir:\n",
    "        loop= loop+1\n",
    "        im_dir = os.path.join(image_dir,sub_dir)+'/images_jpg'\n",
    "\n",
    "        labels_dir = os.path.join(image_dir,sub_dir) + '/gt/'\n",
    "        print(im_dir)\n",
    "        for i,file_name in enumerate(os.listdir(labels_dir)):\n",
    "\n",
    "            if i%50 == 0:\n",
    "                print(f\"there is {i} images processed on the {len(os.listdir(labels_dir))} available.\\n\")\n",
    "            #if i>30:\n",
    "            #    continue\n",
    "                \n",
    "            if(file_name[-3:]!='txt'):\n",
    "                continue\n",
    "            count_images =count_images+1\n",
    "            file_str = file_name.split('.')[0]\n",
    "            \n",
    "        \n",
    "            vid_str, id_str  = file_str.split('_')\n",
    "\n",
    "            \n",
    "            frame_id = int(id_str)\n",
    "            video_id = int(vid_str)\n",
    "            image_id = int(loop*1e8+video_id*1e5+frame_id)\n",
    "\n",
    "            image_name = os.path.join(im_dir, \"{}.jpg\".format(file_str))\n",
    "\n",
    "            if im_size: # Get the size of the images\n",
    "                im_size = False\n",
    "                im = Image.open(image_name)\n",
    "                width, height = im.size\n",
    "                \n",
    "            data[\"images\"].append({\n",
    "                'coco_url': \"unknown\",\n",
    "                'file_name': image_name,\n",
    "                'id': image_id,\n",
    "                'license':1,\n",
    "                #'has_visible_keypoints':True,\n",
    "                'date_captured': \"unknown\",\n",
    "                'width': width,\n",
    "                'height': height})\n",
    "\n",
    "\n",
    "            with open(os.path.join(labels_dir, file_name.split('.')[0]+'.txt')) as f:\n",
    "                keypoints = f.readlines()\n",
    "                keypoints = [s.split(',') for s in keypoints]\n",
    "                keypoints = [list(map(num, s)) for s in keypoints]\n",
    "                \n",
    "            #detect the cars in the image\n",
    "            detections = detector.detectCustomObjectsFromImage( custom_objects=custom, input_image =image_name, output_image_path=out, minimum_percentage_probability=30)\n",
    "            boxes_imageAI = []\n",
    "            for obj in detections:\n",
    "                # Create a Rectangle patch\n",
    "                box = obj[\"box_points\"]\n",
    "                boxes_imageAI.append([box[0], box[1], box[2]-box[0], box[3]-box[1]])\n",
    "            \n",
    "            instances = {}\n",
    "            \n",
    "            assert len(keypoints)!=0\n",
    "            \n",
    "            for keypoint in keypoints:\n",
    "                if keypoint[3] not in instances: #check if keypoint is in the list\n",
    "                    instances[keypoint[3]] = np.zeros((number_keypoints, 3), dtype=np.int32) \n",
    "                instances[keypoint[3]][keypoint[2]-1,0] = keypoint[0] # X coordinate \n",
    "                instances[keypoint[3]][keypoint[2]-1,1] = keypoint[1] # Y Coordinate\n",
    "                if keypoint[4] == 2:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 1\n",
    "                elif keypoint[4] == 1 or keypoint[4] == 3:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 2\n",
    "\n",
    "                if keypoint[0] <= 0 or keypoint[1] > height or keypoint[1] <= 0 or keypoint[0] > width:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 0  #Identify the keypoints outside of the frame of the image            \n",
    "                \n",
    "                        \n",
    "            for instance in instances.values():\n",
    "                \n",
    "                bbox, segmentation, keypoints, num_keypoints = getAnnotation(instance, number_keypoints, width, height)\n",
    "                \n",
    "                if num_keypoints > keypoints_threshold:\n",
    "                    \n",
    "                    #print(len(boxes_imageAI))\n",
    "                    for box in boxes_imageAI:\n",
    "           \n",
    "                        if(compute_IOU(bbox,box) > iou_threshold):\n",
    "                            \n",
    "                            boxes_imageAI.remove(box)                    \n",
    "                    \n",
    "                    \n",
    "                    data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': num_keypoints,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1\n",
    "            \n",
    "            for box in boxes_imageAI:\n",
    "                \n",
    "                keypoints = [0 for a in range(number_keypoints*3)]\n",
    "                hull = Polygon([(box[0],box[1]),(box[0] + box[2], box[1]),\n",
    "                                (box[0],box[1] + box[3]),(box[0] + box[2],box[1] + box[3])]).convex_hull\n",
    "                frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "                hull = hull.intersection(frame).convex_hull\n",
    "                bbox = hull.bounds\n",
    "                w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "                x_o = max(bbox[0]-(w/10),0)\n",
    "                y_o = max(bbox[1]-(h/10),0)\n",
    "                x_i = min(x_o+(w/4)+w,width)\n",
    "                y_i = min(y_o+(h/4)+h,height)\n",
    "                bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "                \n",
    "                seg = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "                seg = [[int(x[0]), int(x[1])] for x in seg]\n",
    "                segmentation = []\n",
    "\n",
    "                for s in seg:\n",
    "                    segmentation.append(s[0])\n",
    "                    segmentation.append(s[1])\n",
    "                \n",
    "                \n",
    "                data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': 0,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_only_test0.3_8_10.json 12761\n"
     ]
    }
   ],
   "source": [
    "json_str = json.dumps(data)\n",
    "\n",
    "print(json_name,count_images)\n",
    "ann_file = os.path.join(output_dir, json_name)\n",
    "if not os.path.exists(output_dir):\n",
    "     os.mkdir(output_dir)\n",
    "with open(ann_file, 'w') as f:\n",
    "     f.write(json_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if car_only :\n",
    "    output_filename = 'car_only_'+ data_type+text\n",
    "else :\n",
    "    output_filename = 'car_'+ data_type+text\n",
    "\n",
    "if data_type=='train':\n",
    "    image_dir = os.path.join(dir_carfusion,\"train\")\n",
    "else:\n",
    "    image_dir = os.path.join(dir_carfusion,\"test\")\n",
    "    \n",
    "\n",
    "output_dir = os.getcwd()+\"/annotations\"\n",
    "path_dir = dir_carfusion\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "data[\"info\"] = {\n",
    "        'url': \"https://www.epfl.ch/labs/vita/\",\n",
    "        'year': time.localtime().tm_year,\n",
    "        'date_created': time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\",\n",
    "            time.localtime()),\n",
    "        'description': \"This is a keypoint dataset for object detection.\",\n",
    "        'version': '1.0',\n",
    "        'contributor': 'VITA laboratory'}\n",
    "\n",
    "data[\"categories\"] = [{'name': 'car',\n",
    "    'id': 1,\n",
    "    'skeleton':skeleton,\n",
    "                       \n",
    "    'supercategory': 'car',\n",
    "    'keypoints': [str(x) for x in range(14)]}]\n",
    "\n",
    "data[\"licenses\"] = [{'id': 1,\n",
    "            'name': \"unknown\",\n",
    "            'url': \"unknown\"}]\n",
    "\n",
    "\n",
    "obj_id = 0\n",
    "# expect sub-folder for subsets\n",
    "data[\"images\"] = []\n",
    "data[\"annotations\"] = []\n",
    "json_name = output_filename+'.json'\n",
    "loop=0\n",
    "count_images=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/bonnesoeur-data/data/carfusion/train/car_butler1/images_jpg\n",
      "there is 0 images processed on the 1172 available.\n",
      "\n",
      "there is 50 images processed on the 1172 available.\n",
      "\n",
      "there is 100 images processed on the 1172 available.\n",
      "\n",
      "there is 150 images processed on the 1172 available.\n",
      "\n",
      "there is 200 images processed on the 1172 available.\n",
      "\n",
      "there is 250 images processed on the 1172 available.\n",
      "\n",
      "there is 300 images processed on the 1172 available.\n",
      "\n",
      "there is 350 images processed on the 1172 available.\n",
      "\n",
      "there is 400 images processed on the 1172 available.\n",
      "\n",
      "there is 450 images processed on the 1172 available.\n",
      "\n",
      "there is 500 images processed on the 1172 available.\n",
      "\n",
      "there is 550 images processed on the 1172 available.\n",
      "\n",
      "there is 600 images processed on the 1172 available.\n",
      "\n",
      "there is 650 images processed on the 1172 available.\n",
      "\n",
      "there is 700 images processed on the 1172 available.\n",
      "\n",
      "there is 750 images processed on the 1172 available.\n",
      "\n",
      "there is 800 images processed on the 1172 available.\n",
      "\n",
      "there is 850 images processed on the 1172 available.\n",
      "\n",
      "there is 900 images processed on the 1172 available.\n",
      "\n",
      "there is 950 images processed on the 1172 available.\n",
      "\n",
      "there is 1000 images processed on the 1172 available.\n",
      "\n",
      "there is 1050 images processed on the 1172 available.\n",
      "\n",
      "there is 1100 images processed on the 1172 available.\n",
      "\n",
      "there is 1150 images processed on the 1172 available.\n",
      "\n",
      "/data/bonnesoeur-data/data/carfusion/train/car_craig2/images_jpg\n",
      "there is 0 images processed on the 3474 available.\n",
      "\n",
      "there is 50 images processed on the 3474 available.\n",
      "\n",
      "there is 100 images processed on the 3474 available.\n",
      "\n",
      "there is 150 images processed on the 3474 available.\n",
      "\n",
      "there is 200 images processed on the 3474 available.\n",
      "\n",
      "there is 250 images processed on the 3474 available.\n",
      "\n",
      "there is 300 images processed on the 3474 available.\n",
      "\n",
      "there is 350 images processed on the 3474 available.\n",
      "\n",
      "there is 400 images processed on the 3474 available.\n",
      "\n",
      "there is 450 images processed on the 3474 available.\n",
      "\n",
      "there is 500 images processed on the 3474 available.\n",
      "\n",
      "there is 550 images processed on the 3474 available.\n",
      "\n",
      "there is 600 images processed on the 3474 available.\n",
      "\n",
      "there is 650 images processed on the 3474 available.\n",
      "\n",
      "there is 700 images processed on the 3474 available.\n",
      "\n",
      "there is 750 images processed on the 3474 available.\n",
      "\n",
      "there is 800 images processed on the 3474 available.\n",
      "\n",
      "there is 850 images processed on the 3474 available.\n",
      "\n",
      "there is 900 images processed on the 3474 available.\n",
      "\n",
      "there is 950 images processed on the 3474 available.\n",
      "\n",
      "there is 1000 images processed on the 3474 available.\n",
      "\n",
      "there is 1050 images processed on the 3474 available.\n",
      "\n",
      "there is 1100 images processed on the 3474 available.\n",
      "\n",
      "there is 1150 images processed on the 3474 available.\n",
      "\n",
      "there is 1200 images processed on the 3474 available.\n",
      "\n",
      "there is 1250 images processed on the 3474 available.\n",
      "\n",
      "there is 1300 images processed on the 3474 available.\n",
      "\n",
      "there is 1350 images processed on the 3474 available.\n",
      "\n",
      "there is 1400 images processed on the 3474 available.\n",
      "\n",
      "there is 1450 images processed on the 3474 available.\n",
      "\n",
      "there is 1500 images processed on the 3474 available.\n",
      "\n",
      "there is 1550 images processed on the 3474 available.\n",
      "\n",
      "there is 1600 images processed on the 3474 available.\n",
      "\n",
      "there is 1650 images processed on the 3474 available.\n",
      "\n",
      "there is 1700 images processed on the 3474 available.\n",
      "\n",
      "there is 1750 images processed on the 3474 available.\n",
      "\n",
      "there is 1800 images processed on the 3474 available.\n",
      "\n",
      "there is 1850 images processed on the 3474 available.\n",
      "\n",
      "there is 1900 images processed on the 3474 available.\n",
      "\n",
      "there is 1950 images processed on the 3474 available.\n",
      "\n",
      "there is 2000 images processed on the 3474 available.\n",
      "\n",
      "there is 2050 images processed on the 3474 available.\n",
      "\n",
      "there is 2100 images processed on the 3474 available.\n",
      "\n",
      "there is 2150 images processed on the 3474 available.\n",
      "\n",
      "there is 2200 images processed on the 3474 available.\n",
      "\n",
      "there is 2250 images processed on the 3474 available.\n",
      "\n",
      "there is 2300 images processed on the 3474 available.\n",
      "\n",
      "there is 2350 images processed on the 3474 available.\n",
      "\n",
      "there is 2400 images processed on the 3474 available.\n",
      "\n",
      "there is 2450 images processed on the 3474 available.\n",
      "\n",
      "there is 2500 images processed on the 3474 available.\n",
      "\n",
      "there is 2550 images processed on the 3474 available.\n",
      "\n",
      "there is 2600 images processed on the 3474 available.\n",
      "\n",
      "there is 2650 images processed on the 3474 available.\n",
      "\n",
      "there is 2700 images processed on the 3474 available.\n",
      "\n",
      "there is 2750 images processed on the 3474 available.\n",
      "\n",
      "there is 2800 images processed on the 3474 available.\n",
      "\n",
      "there is 2850 images processed on the 3474 available.\n",
      "\n",
      "there is 2900 images processed on the 3474 available.\n",
      "\n",
      "there is 2950 images processed on the 3474 available.\n",
      "\n",
      "there is 3000 images processed on the 3474 available.\n",
      "\n",
      "there is 3050 images processed on the 3474 available.\n",
      "\n",
      "there is 3100 images processed on the 3474 available.\n",
      "\n",
      "there is 3150 images processed on the 3474 available.\n",
      "\n",
      "there is 3200 images processed on the 3474 available.\n",
      "\n",
      "there is 3250 images processed on the 3474 available.\n",
      "\n",
      "there is 3300 images processed on the 3474 available.\n",
      "\n",
      "there is 3350 images processed on the 3474 available.\n",
      "\n",
      "there is 3400 images processed on the 3474 available.\n",
      "\n",
      "there is 3450 images processed on the 3474 available.\n",
      "\n",
      "/data/bonnesoeur-data/data/carfusion/train/car_fifth2/images_jpg\n",
      "there is 0 images processed on the 2312 available.\n",
      "\n",
      "there is 50 images processed on the 2312 available.\n",
      "\n",
      "there is 100 images processed on the 2312 available.\n",
      "\n",
      "there is 150 images processed on the 2312 available.\n",
      "\n",
      "there is 200 images processed on the 2312 available.\n",
      "\n",
      "there is 250 images processed on the 2312 available.\n",
      "\n",
      "there is 300 images processed on the 2312 available.\n",
      "\n",
      "there is 350 images processed on the 2312 available.\n",
      "\n",
      "there is 400 images processed on the 2312 available.\n",
      "\n",
      "there is 450 images processed on the 2312 available.\n",
      "\n",
      "there is 500 images processed on the 2312 available.\n",
      "\n",
      "there is 550 images processed on the 2312 available.\n",
      "\n",
      "there is 600 images processed on the 2312 available.\n",
      "\n",
      "there is 650 images processed on the 2312 available.\n",
      "\n",
      "there is 700 images processed on the 2312 available.\n",
      "\n",
      "there is 750 images processed on the 2312 available.\n",
      "\n",
      "there is 800 images processed on the 2312 available.\n",
      "\n",
      "there is 850 images processed on the 2312 available.\n",
      "\n",
      "there is 900 images processed on the 2312 available.\n",
      "\n",
      "there is 950 images processed on the 2312 available.\n",
      "\n",
      "there is 1000 images processed on the 2312 available.\n",
      "\n",
      "there is 1050 images processed on the 2312 available.\n",
      "\n",
      "there is 1100 images processed on the 2312 available.\n",
      "\n",
      "there is 1150 images processed on the 2312 available.\n",
      "\n",
      "there is 1200 images processed on the 2312 available.\n",
      "\n",
      "there is 1250 images processed on the 2312 available.\n",
      "\n",
      "there is 1300 images processed on the 2312 available.\n",
      "\n",
      "there is 1350 images processed on the 2312 available.\n",
      "\n",
      "there is 1400 images processed on the 2312 available.\n",
      "\n",
      "there is 1450 images processed on the 2312 available.\n",
      "\n",
      "there is 1500 images processed on the 2312 available.\n",
      "\n",
      "there is 1550 images processed on the 2312 available.\n",
      "\n",
      "there is 1600 images processed on the 2312 available.\n",
      "\n",
      "there is 1650 images processed on the 2312 available.\n",
      "\n",
      "there is 1700 images processed on the 2312 available.\n",
      "\n",
      "there is 1750 images processed on the 2312 available.\n",
      "\n",
      "there is 1800 images processed on the 2312 available.\n",
      "\n",
      "there is 1850 images processed on the 2312 available.\n",
      "\n",
      "there is 1900 images processed on the 2312 available.\n",
      "\n",
      "there is 1950 images processed on the 2312 available.\n",
      "\n",
      "there is 2000 images processed on the 2312 available.\n",
      "\n",
      "there is 2050 images processed on the 2312 available.\n",
      "\n",
      "there is 2100 images processed on the 2312 available.\n",
      "\n",
      "there is 2150 images processed on the 2312 available.\n",
      "\n",
      "there is 2200 images processed on the 2312 available.\n",
      "\n",
      "there is 2250 images processed on the 2312 available.\n",
      "\n",
      "there is 2300 images processed on the 2312 available.\n",
      "\n",
      "/data/bonnesoeur-data/data/carfusion/train/car_craig1/images_jpg\n",
      "there is 0 images processed on the 3674 available.\n",
      "\n",
      "there is 50 images processed on the 3674 available.\n",
      "\n",
      "there is 100 images processed on the 3674 available.\n",
      "\n",
      "there is 150 images processed on the 3674 available.\n",
      "\n",
      "there is 200 images processed on the 3674 available.\n",
      "\n",
      "there is 250 images processed on the 3674 available.\n",
      "\n",
      "there is 300 images processed on the 3674 available.\n",
      "\n",
      "there is 350 images processed on the 3674 available.\n",
      "\n",
      "there is 400 images processed on the 3674 available.\n",
      "\n",
      "there is 450 images processed on the 3674 available.\n",
      "\n",
      "there is 500 images processed on the 3674 available.\n",
      "\n",
      "there is 550 images processed on the 3674 available.\n",
      "\n",
      "there is 600 images processed on the 3674 available.\n",
      "\n",
      "there is 650 images processed on the 3674 available.\n",
      "\n",
      "there is 700 images processed on the 3674 available.\n",
      "\n",
      "there is 750 images processed on the 3674 available.\n",
      "\n",
      "there is 800 images processed on the 3674 available.\n",
      "\n",
      "there is 850 images processed on the 3674 available.\n",
      "\n",
      "there is 900 images processed on the 3674 available.\n",
      "\n",
      "there is 950 images processed on the 3674 available.\n",
      "\n",
      "there is 1000 images processed on the 3674 available.\n",
      "\n",
      "there is 1050 images processed on the 3674 available.\n",
      "\n",
      "there is 1100 images processed on the 3674 available.\n",
      "\n",
      "there is 1150 images processed on the 3674 available.\n",
      "\n",
      "there is 1200 images processed on the 3674 available.\n",
      "\n",
      "there is 1250 images processed on the 3674 available.\n",
      "\n",
      "there is 1300 images processed on the 3674 available.\n",
      "\n",
      "there is 1350 images processed on the 3674 available.\n",
      "\n",
      "there is 1400 images processed on the 3674 available.\n",
      "\n",
      "there is 1450 images processed on the 3674 available.\n",
      "\n",
      "there is 1500 images processed on the 3674 available.\n",
      "\n",
      "there is 1550 images processed on the 3674 available.\n",
      "\n",
      "there is 1600 images processed on the 3674 available.\n",
      "\n",
      "there is 1650 images processed on the 3674 available.\n",
      "\n",
      "there is 1700 images processed on the 3674 available.\n",
      "\n",
      "there is 1750 images processed on the 3674 available.\n",
      "\n",
      "there is 1800 images processed on the 3674 available.\n",
      "\n",
      "there is 1850 images processed on the 3674 available.\n",
      "\n",
      "there is 1900 images processed on the 3674 available.\n",
      "\n",
      "there is 1950 images processed on the 3674 available.\n",
      "\n",
      "there is 2000 images processed on the 3674 available.\n",
      "\n",
      "there is 2050 images processed on the 3674 available.\n",
      "\n",
      "there is 2100 images processed on the 3674 available.\n",
      "\n",
      "there is 2150 images processed on the 3674 available.\n",
      "\n",
      "there is 2200 images processed on the 3674 available.\n",
      "\n",
      "there is 2250 images processed on the 3674 available.\n",
      "\n",
      "there is 2300 images processed on the 3674 available.\n",
      "\n",
      "there is 2350 images processed on the 3674 available.\n",
      "\n",
      "there is 2400 images processed on the 3674 available.\n",
      "\n",
      "there is 2450 images processed on the 3674 available.\n",
      "\n",
      "there is 2500 images processed on the 3674 available.\n",
      "\n",
      "there is 2550 images processed on the 3674 available.\n",
      "\n",
      "there is 2600 images processed on the 3674 available.\n",
      "\n",
      "there is 2650 images processed on the 3674 available.\n",
      "\n",
      "there is 2700 images processed on the 3674 available.\n",
      "\n",
      "there is 2750 images processed on the 3674 available.\n",
      "\n",
      "there is 2800 images processed on the 3674 available.\n",
      "\n",
      "there is 2850 images processed on the 3674 available.\n",
      "\n",
      "there is 2900 images processed on the 3674 available.\n",
      "\n",
      "there is 2950 images processed on the 3674 available.\n",
      "\n",
      "there is 3000 images processed on the 3674 available.\n",
      "\n",
      "there is 3050 images processed on the 3674 available.\n",
      "\n",
      "there is 3100 images processed on the 3674 available.\n",
      "\n",
      "there is 3150 images processed on the 3674 available.\n",
      "\n",
      "there is 3200 images processed on the 3674 available.\n",
      "\n",
      "there is 3250 images processed on the 3674 available.\n",
      "\n",
      "there is 3300 images processed on the 3674 available.\n",
      "\n",
      "there is 3350 images processed on the 3674 available.\n",
      "\n",
      "there is 3400 images processed on the 3674 available.\n",
      "\n",
      "there is 3450 images processed on the 3674 available.\n",
      "\n",
      "there is 3500 images processed on the 3674 available.\n",
      "\n",
      "there is 3550 images processed on the 3674 available.\n",
      "\n",
      "there is 3600 images processed on the 3674 available.\n",
      "\n",
      "there is 3650 images processed on the 3674 available.\n",
      "\n",
      "/data/bonnesoeur-data/data/carfusion/train/car_butler2/images_jpg\n",
      "there is 0 images processed on the 1352 available.\n",
      "\n",
      "there is 50 images processed on the 1352 available.\n",
      "\n",
      "there is 100 images processed on the 1352 available.\n",
      "\n",
      "there is 150 images processed on the 1352 available.\n",
      "\n",
      "there is 200 images processed on the 1352 available.\n",
      "\n",
      "there is 250 images processed on the 1352 available.\n",
      "\n",
      "there is 300 images processed on the 1352 available.\n",
      "\n",
      "there is 350 images processed on the 1352 available.\n",
      "\n",
      "there is 400 images processed on the 1352 available.\n",
      "\n",
      "there is 450 images processed on the 1352 available.\n",
      "\n",
      "there is 500 images processed on the 1352 available.\n",
      "\n",
      "there is 550 images processed on the 1352 available.\n",
      "\n",
      "there is 600 images processed on the 1352 available.\n",
      "\n",
      "there is 650 images processed on the 1352 available.\n",
      "\n",
      "there is 700 images processed on the 1352 available.\n",
      "\n",
      "there is 750 images processed on the 1352 available.\n",
      "\n",
      "there is 800 images processed on the 1352 available.\n",
      "\n",
      "there is 850 images processed on the 1352 available.\n",
      "\n",
      "there is 900 images processed on the 1352 available.\n",
      "\n",
      "there is 950 images processed on the 1352 available.\n",
      "\n",
      "there is 1000 images processed on the 1352 available.\n",
      "\n",
      "there is 1050 images processed on the 1352 available.\n",
      "\n",
      "there is 1100 images processed on the 1352 available.\n",
      "\n",
      "there is 1150 images processed on the 1352 available.\n",
      "\n",
      "there is 1200 images processed on the 1352 available.\n",
      "\n",
      "there is 1250 images processed on the 1352 available.\n",
      "\n",
      "there is 1300 images processed on the 1352 available.\n",
      "\n",
      "there is 1350 images processed on the 1352 available.\n",
      "\n",
      "/data/bonnesoeur-data/data/carfusion/train/car_morewood2/images_jpg\n",
      "there is 0 images processed on the 3690 available.\n",
      "\n",
      "there is 50 images processed on the 3690 available.\n",
      "\n",
      "there is 100 images processed on the 3690 available.\n",
      "\n",
      "there is 150 images processed on the 3690 available.\n",
      "\n",
      "there is 200 images processed on the 3690 available.\n",
      "\n",
      "there is 250 images processed on the 3690 available.\n",
      "\n",
      "there is 300 images processed on the 3690 available.\n",
      "\n",
      "there is 350 images processed on the 3690 available.\n",
      "\n",
      "there is 400 images processed on the 3690 available.\n",
      "\n",
      "there is 450 images processed on the 3690 available.\n",
      "\n",
      "there is 500 images processed on the 3690 available.\n",
      "\n",
      "there is 550 images processed on the 3690 available.\n",
      "\n",
      "there is 600 images processed on the 3690 available.\n",
      "\n",
      "there is 650 images processed on the 3690 available.\n",
      "\n",
      "there is 700 images processed on the 3690 available.\n",
      "\n",
      "there is 750 images processed on the 3690 available.\n",
      "\n",
      "there is 800 images processed on the 3690 available.\n",
      "\n",
      "there is 850 images processed on the 3690 available.\n",
      "\n",
      "there is 900 images processed on the 3690 available.\n",
      "\n",
      "there is 950 images processed on the 3690 available.\n",
      "\n",
      "there is 1000 images processed on the 3690 available.\n",
      "\n",
      "there is 1050 images processed on the 3690 available.\n",
      "\n",
      "there is 1100 images processed on the 3690 available.\n",
      "\n",
      "there is 1150 images processed on the 3690 available.\n",
      "\n",
      "there is 1200 images processed on the 3690 available.\n",
      "\n",
      "there is 1250 images processed on the 3690 available.\n",
      "\n",
      "there is 1300 images processed on the 3690 available.\n",
      "\n",
      "there is 1350 images processed on the 3690 available.\n",
      "\n",
      "there is 1400 images processed on the 3690 available.\n",
      "\n",
      "there is 1450 images processed on the 3690 available.\n",
      "\n",
      "there is 1500 images processed on the 3690 available.\n",
      "\n",
      "there is 1550 images processed on the 3690 available.\n",
      "\n",
      "there is 1600 images processed on the 3690 available.\n",
      "\n",
      "there is 1650 images processed on the 3690 available.\n",
      "\n",
      "there is 1700 images processed on the 3690 available.\n",
      "\n",
      "there is 1750 images processed on the 3690 available.\n",
      "\n",
      "there is 1800 images processed on the 3690 available.\n",
      "\n",
      "there is 1850 images processed on the 3690 available.\n",
      "\n",
      "there is 1900 images processed on the 3690 available.\n",
      "\n",
      "there is 1950 images processed on the 3690 available.\n",
      "\n",
      "there is 2000 images processed on the 3690 available.\n",
      "\n",
      "there is 2050 images processed on the 3690 available.\n",
      "\n",
      "there is 2100 images processed on the 3690 available.\n",
      "\n",
      "there is 2150 images processed on the 3690 available.\n",
      "\n",
      "there is 2200 images processed on the 3690 available.\n",
      "\n",
      "there is 2250 images processed on the 3690 available.\n",
      "\n",
      "there is 2300 images processed on the 3690 available.\n",
      "\n",
      "there is 2350 images processed on the 3690 available.\n",
      "\n",
      "there is 2400 images processed on the 3690 available.\n",
      "\n",
      "there is 2450 images processed on the 3690 available.\n",
      "\n",
      "there is 2500 images processed on the 3690 available.\n",
      "\n",
      "there is 2550 images processed on the 3690 available.\n",
      "\n",
      "there is 2600 images processed on the 3690 available.\n",
      "\n",
      "there is 2650 images processed on the 3690 available.\n",
      "\n",
      "there is 2700 images processed on the 3690 available.\n",
      "\n",
      "there is 2750 images processed on the 3690 available.\n",
      "\n",
      "there is 2800 images processed on the 3690 available.\n",
      "\n",
      "there is 2850 images processed on the 3690 available.\n",
      "\n",
      "there is 2900 images processed on the 3690 available.\n",
      "\n",
      "there is 2950 images processed on the 3690 available.\n",
      "\n",
      "there is 3000 images processed on the 3690 available.\n",
      "\n",
      "there is 3050 images processed on the 3690 available.\n",
      "\n",
      "there is 3100 images processed on the 3690 available.\n",
      "\n",
      "there is 3150 images processed on the 3690 available.\n",
      "\n",
      "there is 3200 images processed on the 3690 available.\n",
      "\n",
      "there is 3250 images processed on the 3690 available.\n",
      "\n",
      "there is 3300 images processed on the 3690 available.\n",
      "\n",
      "there is 3350 images processed on the 3690 available.\n",
      "\n",
      "there is 3400 images processed on the 3690 available.\n",
      "\n",
      "there is 3450 images processed on the 3690 available.\n",
      "\n",
      "there is 3500 images processed on the 3690 available.\n",
      "\n",
      "there is 3550 images processed on the 3690 available.\n",
      "\n",
      "there is 3600 images processed on the 3690 available.\n",
      "\n",
      "there is 3650 images processed on the 3690 available.\n",
      "\n",
      "/data/bonnesoeur-data/data/carfusion/train/car_morewood1/images_jpg\n",
      "there is 0 images processed on the 3219 available.\n",
      "\n",
      "there is 50 images processed on the 3219 available.\n",
      "\n",
      "there is 100 images processed on the 3219 available.\n",
      "\n",
      "there is 150 images processed on the 3219 available.\n",
      "\n",
      "there is 200 images processed on the 3219 available.\n",
      "\n",
      "there is 250 images processed on the 3219 available.\n",
      "\n",
      "there is 300 images processed on the 3219 available.\n",
      "\n",
      "there is 350 images processed on the 3219 available.\n",
      "\n",
      "there is 400 images processed on the 3219 available.\n",
      "\n",
      "there is 450 images processed on the 3219 available.\n",
      "\n",
      "there is 500 images processed on the 3219 available.\n",
      "\n",
      "there is 550 images processed on the 3219 available.\n",
      "\n",
      "there is 600 images processed on the 3219 available.\n",
      "\n",
      "there is 650 images processed on the 3219 available.\n",
      "\n",
      "there is 700 images processed on the 3219 available.\n",
      "\n",
      "there is 750 images processed on the 3219 available.\n",
      "\n",
      "there is 800 images processed on the 3219 available.\n",
      "\n",
      "there is 850 images processed on the 3219 available.\n",
      "\n",
      "there is 900 images processed on the 3219 available.\n",
      "\n",
      "there is 950 images processed on the 3219 available.\n",
      "\n",
      "there is 1000 images processed on the 3219 available.\n",
      "\n",
      "there is 1050 images processed on the 3219 available.\n",
      "\n",
      "there is 1100 images processed on the 3219 available.\n",
      "\n",
      "there is 1150 images processed on the 3219 available.\n",
      "\n",
      "there is 1200 images processed on the 3219 available.\n",
      "\n",
      "there is 1250 images processed on the 3219 available.\n",
      "\n",
      "there is 1300 images processed on the 3219 available.\n",
      "\n",
      "there is 1350 images processed on the 3219 available.\n",
      "\n",
      "there is 1400 images processed on the 3219 available.\n",
      "\n",
      "there is 1450 images processed on the 3219 available.\n",
      "\n",
      "there is 1500 images processed on the 3219 available.\n",
      "\n",
      "there is 1550 images processed on the 3219 available.\n",
      "\n",
      "there is 1600 images processed on the 3219 available.\n",
      "\n",
      "there is 1650 images processed on the 3219 available.\n",
      "\n",
      "there is 1700 images processed on the 3219 available.\n",
      "\n",
      "there is 1750 images processed on the 3219 available.\n",
      "\n",
      "there is 1800 images processed on the 3219 available.\n",
      "\n",
      "there is 1850 images processed on the 3219 available.\n",
      "\n",
      "there is 1900 images processed on the 3219 available.\n",
      "\n",
      "there is 1950 images processed on the 3219 available.\n",
      "\n",
      "there is 2000 images processed on the 3219 available.\n",
      "\n",
      "there is 2050 images processed on the 3219 available.\n",
      "\n",
      "there is 2100 images processed on the 3219 available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sub_dir in os.listdir(image_dir):\n",
    "    im_size = True\n",
    "    \n",
    "    if sub_dir[:3] == 'car':\n",
    "        loop= loop+1\n",
    "        im_dir = os.path.join(image_dir,sub_dir)+'/images_jpg'\n",
    "\n",
    "        labels_dir = os.path.join(image_dir,sub_dir) + '/gt/'\n",
    "        print(im_dir)\n",
    "        for i,file_name in enumerate(os.listdir(labels_dir)):\n",
    "\n",
    "            if i%50 == 0:\n",
    "                print(f\"there is {i} images processed on the {len(os.listdir(labels_dir))} available.\\n\")\n",
    "            #if i>30:\n",
    "            #    continue\n",
    "                \n",
    "            if(file_name[-3:]!='txt'):\n",
    "                continue\n",
    "            count_images =count_images+1\n",
    "            file_str = file_name.split('.')[0]\n",
    "            \n",
    "        \n",
    "            vid_str, id_str  = file_str.split('_')\n",
    "\n",
    "            \n",
    "            frame_id = int(id_str)\n",
    "            video_id = int(vid_str)\n",
    "            image_id = int(loop*1e8+video_id*1e5+frame_id)\n",
    "\n",
    "            image_name = os.path.join(im_dir, \"{}.jpg\".format(file_str))\n",
    "\n",
    "            if im_size: # Get the size of the images\n",
    "                im_size = False\n",
    "                im = Image.open(image_name)\n",
    "                width, height = im.size\n",
    "                \n",
    "            data[\"images\"].append({\n",
    "                'coco_url': \"unknown\",\n",
    "                'file_name': image_name,\n",
    "                'id': image_id,\n",
    "                'license':1,\n",
    "                #'has_visible_keypoints':True,\n",
    "                'date_captured': \"unknown\",\n",
    "                'width': width,\n",
    "                'height': height})\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            with open(os.path.join(labels_dir, file_name.split('.')[0]+'.txt')) as f:\n",
    "                keypoints = f.readlines()\n",
    "                keypoints = [s.split(',') for s in keypoints]\n",
    "                keypoints = [list(map(num, s)) for s in keypoints]\n",
    "                \n",
    "            #detect the cars in the image\n",
    "            detections = detector.detectCustomObjectsFromImage( custom_objects=custom, input_image =image_name,  output_image_path=out, minimum_percentage_probability=30)\n",
    "            boxes_imageAI = []\n",
    "            for obj in detections:\n",
    "                # Create a Rectangle patch\n",
    "                box = obj[\"box_points\"]\n",
    "                boxes_imageAI.append([box[0], box[1], box[2]-box[0], box[3]-box[1]])\n",
    "            \n",
    "            instances = {}\n",
    "            \n",
    "            assert len(keypoints)!=0\n",
    "            \n",
    "            for keypoint in keypoints:\n",
    "                if keypoint[3] not in instances: #check if keypoint is in the list\n",
    "                    instances[keypoint[3]] = np.zeros((number_keypoints, 3), dtype=np.int32) \n",
    "                instances[keypoint[3]][keypoint[2]-1,0] = keypoint[0] # X coordinate \n",
    "                instances[keypoint[3]][keypoint[2]-1,1] = keypoint[1] # Y Coordinate\n",
    "                if keypoint[4] == 2:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 1\n",
    "                elif keypoint[4] == 1 or keypoint[4] == 3:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 2\n",
    "\n",
    "                if keypoint[0] <= 0 or keypoint[1] > height or keypoint[1] <= 0 or keypoint[0] > width:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 0  #Identify the keypoints outside of the frame of the image            \n",
    "                \n",
    "                        \n",
    "            for instance in instances.values():\n",
    "                \n",
    "                bbox, segmentation, keypoints, num_keypoints = getAnnotation(instance, number_keypoints, width, height)\n",
    "                \n",
    "                if num_keypoints > keypoints_threshold:\n",
    "                    \n",
    "                    #print(len(boxes_imageAI))\n",
    "                    for box in boxes_imageAI:\n",
    "\n",
    "                        \n",
    "                        if(compute_IOU(bbox,box) > iou_threshold):\n",
    "                            \n",
    "                            boxes_imageAI.remove(box)\n",
    "                    #print(len(boxes_imageAI))\n",
    "                    \n",
    "                    data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': num_keypoints,\n",
    "                        'keypoints':keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1\n",
    "            \n",
    "            for box in boxes_imageAI:\n",
    "                \n",
    "                keypoints = [0 for a in range(number_keypoints*3)]\n",
    "                hull = Polygon([(box[0],box[1]),(box[0] + box[2], box[1]),\n",
    "                                (box[0],box[1] + box[3]),(box[0] + box[2],box[1] + box[3])]).convex_hull\n",
    "                frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "                hull = hull.intersection(frame).convex_hull\n",
    "                bbox = hull.bounds\n",
    "                w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "                x_o = max(bbox[0]-(w/10),0)\n",
    "                y_o = max(bbox[1]-(h/10),0)\n",
    "                x_i = min(x_o+(w/4)+w,width)\n",
    "                y_i = min(y_o+(h/4)+h,height)\n",
    "                bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "                \n",
    "                seg = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "                seg = [[int(x[0]), int(x[1])] for x in seg]\n",
    "                segmentation = []\n",
    "\n",
    "                for s in seg:\n",
    "                    segmentation.append(s[0])\n",
    "                    segmentation.append(s[1])\n",
    "                \n",
    "                \n",
    "                data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': 0,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(data)\n",
    "\n",
    "print(json_name,count_images)\n",
    "ann_file = os.path.join(output_dir, json_name)\n",
    "if not os.path.exists(output_dir):\n",
    "     os.mkdir(output_dir)\n",
    "with open(ann_file, 'w') as f:\n",
    "     f.write(json_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def num(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return int(float(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to process the carfusion dataset to make it readable by openpifpaf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keypoints will be processed in a COCO formatting and a car detection with ImageAi will be performed to detect the cars without bounding box. In fact, the carfusion dataset only provides a list of keypoints and no information about the other non annotated cars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the ImageAi detection on the images, we determine an IOU to applicate on the images in order to annotate only the cars without keypoints (default = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageAi \n",
    "The objective is to detect the cars which are not annotated. This way, we will be able to create a bounding box for the cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings of the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"./model/yolo.h5\") #link of the yolo model for car detection\n",
    "# You can download it here : https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detector is configured to detect only cars, bus and trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU = 0.3\n",
    "car_only = False                     #Yolov3 detects the cars, buses and van, by puting car_only to True, it will only detect the cars\n",
    "dir_carfusion=\"./datasets/carfusion\" #Directory of carfusion\n",
    "number_keypoints = 14                #Number of keypoint for the cars "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to remove some keypoints in the carfusion dataset, you can use the span0 and span1 variables which will remove the keypoints in the interval :  ]span0, span1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Used to remove a set of keypoints in the interval ]span0, span1]\n",
    "span0 = span1 = 0\n",
    "#span0 = 8\n",
    "#span1 = 10\n",
    "\n",
    "text = str(IOU)\n",
    "\n",
    "if span0 != span1:\n",
    "    text+=\"_\"+str(span0)+\"_\"+str(span1)\n",
    "\n",
    "keypoints_threshold = 1 # minimum number of keypoints to consider the cars in both the training and validation dataset\n",
    "\n",
    "\n",
    "out = \"./1.jpg\" # choose whatever name/place that you want (only used during processing, nothing is saved)\n",
    "\n",
    "if car_only:\n",
    "    custom = detector.CustomObjects(car=True, truck=False, bus=False)\n",
    "else: \n",
    "    custom = detector.CustomObjects(car=True, truck=True, bus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton =[\n",
    "            [1, 2], [1,3], [2,4], [3,4],    #wheels\n",
    "            [1,5], [2,6],[3,7], [4,8],      #Links between the wheels and the lights\n",
    "            #[5,6], [7,8],                   #links between the lights\n",
    "            [5,9], [6,10],                  #links between the mirrors and the front lights\n",
    "            [5,11],[6,12], [7,13],[8,14],   #links between the lights and the windshiel/rear\n",
    "            [11,12],[11,13],[12,14],[13,14] #links between the rear and the windshiel ,\n",
    "            ]\n",
    "    \n",
    "    \n",
    "COCO_KEYPOINTS = [\n",
    "    'front_left_wheel',         #1          0\n",
    "    'front_right_wheel',        #2          1\n",
    "    'back_left_wheel',          #3          2\n",
    "    'back_right_wheel',         #4          3\n",
    "    'front_left_light',         #5          4\n",
    "    'front_right_light',        #6          5\n",
    "    'back_left_light',          #7          6\n",
    "    'back_right_light',         #8          7\n",
    "    'left_mirror',              #9          8\n",
    "    'right_mirror',             #10         9\n",
    "    'upper_left_windshield',    #11         10\n",
    "    'upper_right_windshield',   #12         11\n",
    "    'upper_left_rear',          #13         12\n",
    "    'upper_right_rear',         #14         13\n",
    "]\n",
    "\n",
    "reorder_keypoints = [1,0,3,2,5,4,7,6,13,8,10,9,12,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnnotation(instance, total_keypoints ,width, height):\n",
    "\n",
    "    valid_2 = instance[:, 2] == 1\n",
    "    valid = instance[:, 2] == 2\n",
    "\n",
    "    visible = np.logical_or(valid, valid_2)\n",
    "    num_keypoints = int(np.sum(visible))\n",
    "\n",
    "    keypoints = np.zeros((total_keypoints,3), dtype=np.int32)\n",
    "    try:\n",
    "        hull = Polygon([(x[0], x[1]) for x in instance[visible, :2]]).convex_hull\n",
    "        frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "        hull = hull.intersection(frame).convex_hull\n",
    "\n",
    "        bbox = hull.bounds\n",
    "        w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "        x_o = max(bbox[0]-(w/10),0)\n",
    "        y_o = max(bbox[1]-(h/10),0)\n",
    "        x_i = min(x_o+(w/4)+w,width)\n",
    "        y_i = min(y_o+(h/4)+h,height)\n",
    "        bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "\n",
    "        segmentation = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "        segmentation = [[int(x[0]), int(x[1])] for x in segmentation]\n",
    "\n",
    "        keypoints[:, :] = instance[:, :]\n",
    "\n",
    "    except:\n",
    "        bbox = [0, 0, 0, 0]\n",
    "        segmentation = []\n",
    "\n",
    "    keypoints = keypoints[reorder_keypoints,:]\n",
    "    #print(keypoints.shape)\n",
    "    keypoints = np.reshape(keypoints, (total_keypoints*3,))\n",
    "    keypoints = keypoints.tolist()\n",
    "    keypoints = [int(x) for x in keypoints]\n",
    "    \n",
    "    #print(keypoints)\n",
    "\n",
    "    seg = []\n",
    "    for s in segmentation:\n",
    "        seg.append(s[0])\n",
    "        seg.append(s[1])\n",
    "\n",
    "\n",
    "    return bbox, seg, keypoints, num_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IOU(boxA, boxB):\n",
    "\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0]+boxA[2], boxB[0]+boxB[2])\n",
    "    yB = min(boxA[1]+boxA[3], boxB[1]+ boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = boxA[2]*boxA[3]\n",
    "    boxBArea = boxB[2]*boxB[3]\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return abs(iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of our data structure and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type='test'\n",
    "\n",
    "iou_threshold = IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if car_only:\n",
    "    output_filename = 'car_only_'+ data_type+text\n",
    "else:\n",
    "    output_filename = 'car_'+ data_type+text\n",
    "\n",
    "if data_type=='train':\n",
    "    image_dir = os.path.join(dir_carfusion,\"train\")\n",
    "else:\n",
    "    image_dir = os.path.join(dir_carfusion,\"test\")\n",
    "    \n",
    "output_dir = os.getcwd()+\"/annotations\"\n",
    "path_dir = dir_carfusion\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "data[\"info\"] = {\n",
    "        'url': \"https://www.epfl.ch/labs/vita/\",\n",
    "        'year': time.localtime().tm_year,\n",
    "        'date_created': time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\",\n",
    "            time.localtime()),\n",
    "        'description': \"This is a keypoint dataset for object detection.\",\n",
    "        'version': '1.0',\n",
    "        'contributor': 'VITA laboratory'}\n",
    "\n",
    "data[\"categories\"] = [{'name': 'car',\n",
    "    'id': 1,\n",
    "    'skeleton':skeleton,\n",
    "                       \n",
    "    'supercategory': 'car',\n",
    "    'keypoints': [str(x) for x in range(14)]}]\n",
    "\n",
    "data[\"licenses\"] = [{'id': 1,\n",
    "            'name': \"unknown\",\n",
    "            'url': \"unknown\"}]\n",
    "\n",
    "\n",
    "obj_id = 0\n",
    "# expect sub-folder for subsets\n",
    "data[\"images\"] = []\n",
    "data[\"annotations\"] = []\n",
    "json_name = output_filename+'.json'\n",
    "loop=0\n",
    "count_images=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/carfusion/test/car_penn1/images_jpg\n",
      "there is 0 images processed on the 6919 available.\n",
      "\n",
      "there is 50 images processed on the 6919 available.\n",
      "\n",
      "there is 100 images processed on the 6919 available.\n",
      "\n",
      "there is 150 images processed on the 6919 available.\n",
      "\n",
      "there is 200 images processed on the 6919 available.\n",
      "\n",
      "there is 250 images processed on the 6919 available.\n",
      "\n",
      "there is 300 images processed on the 6919 available.\n",
      "\n",
      "there is 350 images processed on the 6919 available.\n",
      "\n",
      "there is 400 images processed on the 6919 available.\n",
      "\n",
      "there is 450 images processed on the 6919 available.\n",
      "\n",
      "there is 500 images processed on the 6919 available.\n",
      "\n",
      "there is 550 images processed on the 6919 available.\n",
      "\n",
      "there is 600 images processed on the 6919 available.\n",
      "\n",
      "there is 650 images processed on the 6919 available.\n",
      "\n",
      "there is 700 images processed on the 6919 available.\n",
      "\n",
      "there is 750 images processed on the 6919 available.\n",
      "\n",
      "there is 800 images processed on the 6919 available.\n",
      "\n",
      "there is 850 images processed on the 6919 available.\n",
      "\n",
      "there is 900 images processed on the 6919 available.\n",
      "\n",
      "there is 950 images processed on the 6919 available.\n",
      "\n",
      "there is 1000 images processed on the 6919 available.\n",
      "\n",
      "there is 1050 images processed on the 6919 available.\n",
      "\n",
      "there is 1100 images processed on the 6919 available.\n",
      "\n",
      "there is 1150 images processed on the 6919 available.\n",
      "\n",
      "there is 1200 images processed on the 6919 available.\n",
      "\n",
      "there is 1250 images processed on the 6919 available.\n",
      "\n",
      "there is 1300 images processed on the 6919 available.\n",
      "\n",
      "there is 1350 images processed on the 6919 available.\n",
      "\n",
      "there is 1400 images processed on the 6919 available.\n",
      "\n",
      "there is 1450 images processed on the 6919 available.\n",
      "\n",
      "there is 1500 images processed on the 6919 available.\n",
      "\n",
      "there is 1550 images processed on the 6919 available.\n",
      "\n",
      "there is 1600 images processed on the 6919 available.\n",
      "\n",
      "there is 1650 images processed on the 6919 available.\n",
      "\n",
      "there is 1700 images processed on the 6919 available.\n",
      "\n",
      "there is 1750 images processed on the 6919 available.\n",
      "\n",
      "there is 1800 images processed on the 6919 available.\n",
      "\n",
      "there is 1850 images processed on the 6919 available.\n",
      "\n",
      "there is 1900 images processed on the 6919 available.\n",
      "\n",
      "there is 1950 images processed on the 6919 available.\n",
      "\n",
      "there is 2000 images processed on the 6919 available.\n",
      "\n",
      "there is 2050 images processed on the 6919 available.\n",
      "\n",
      "there is 2100 images processed on the 6919 available.\n",
      "\n",
      "there is 2150 images processed on the 6919 available.\n",
      "\n",
      "there is 2200 images processed on the 6919 available.\n",
      "\n",
      "there is 2250 images processed on the 6919 available.\n",
      "\n",
      "there is 2300 images processed on the 6919 available.\n",
      "\n",
      "there is 2350 images processed on the 6919 available.\n",
      "\n",
      "there is 2400 images processed on the 6919 available.\n",
      "\n",
      "there is 2450 images processed on the 6919 available.\n",
      "\n",
      "there is 2500 images processed on the 6919 available.\n",
      "\n",
      "there is 2550 images processed on the 6919 available.\n",
      "\n",
      "there is 2600 images processed on the 6919 available.\n",
      "\n",
      "there is 2650 images processed on the 6919 available.\n",
      "\n",
      "there is 2700 images processed on the 6919 available.\n",
      "\n",
      "there is 2750 images processed on the 6919 available.\n",
      "\n",
      "there is 2800 images processed on the 6919 available.\n",
      "\n",
      "there is 2850 images processed on the 6919 available.\n",
      "\n",
      "there is 2900 images processed on the 6919 available.\n",
      "\n",
      "there is 2950 images processed on the 6919 available.\n",
      "\n",
      "there is 3000 images processed on the 6919 available.\n",
      "\n",
      "there is 3050 images processed on the 6919 available.\n",
      "\n",
      "there is 3100 images processed on the 6919 available.\n",
      "\n",
      "there is 3150 images processed on the 6919 available.\n",
      "\n",
      "there is 3200 images processed on the 6919 available.\n",
      "\n",
      "there is 3250 images processed on the 6919 available.\n",
      "\n",
      "there is 3300 images processed on the 6919 available.\n",
      "\n",
      "there is 3350 images processed on the 6919 available.\n",
      "\n",
      "there is 3400 images processed on the 6919 available.\n",
      "\n",
      "there is 3450 images processed on the 6919 available.\n",
      "\n",
      "there is 3500 images processed on the 6919 available.\n",
      "\n",
      "there is 3550 images processed on the 6919 available.\n",
      "\n",
      "there is 3600 images processed on the 6919 available.\n",
      "\n",
      "there is 3650 images processed on the 6919 available.\n",
      "\n",
      "there is 3700 images processed on the 6919 available.\n",
      "\n",
      "there is 3750 images processed on the 6919 available.\n",
      "\n",
      "there is 3800 images processed on the 6919 available.\n",
      "\n",
      "there is 3850 images processed on the 6919 available.\n",
      "\n",
      "there is 3900 images processed on the 6919 available.\n",
      "\n",
      "there is 3950 images processed on the 6919 available.\n",
      "\n",
      "there is 4000 images processed on the 6919 available.\n",
      "\n",
      "there is 4050 images processed on the 6919 available.\n",
      "\n",
      "there is 4100 images processed on the 6919 available.\n",
      "\n",
      "there is 4150 images processed on the 6919 available.\n",
      "\n",
      "there is 4200 images processed on the 6919 available.\n",
      "\n",
      "there is 4250 images processed on the 6919 available.\n",
      "\n",
      "there is 4300 images processed on the 6919 available.\n",
      "\n",
      "there is 4350 images processed on the 6919 available.\n",
      "\n",
      "there is 4400 images processed on the 6919 available.\n",
      "\n",
      "there is 4450 images processed on the 6919 available.\n",
      "\n",
      "there is 4500 images processed on the 6919 available.\n",
      "\n",
      "there is 4550 images processed on the 6919 available.\n",
      "\n",
      "there is 4600 images processed on the 6919 available.\n",
      "\n",
      "there is 4650 images processed on the 6919 available.\n",
      "\n",
      "there is 4700 images processed on the 6919 available.\n",
      "\n",
      "there is 4750 images processed on the 6919 available.\n",
      "\n",
      "there is 4800 images processed on the 6919 available.\n",
      "\n",
      "there is 4850 images processed on the 6919 available.\n",
      "\n",
      "there is 4900 images processed on the 6919 available.\n",
      "\n",
      "there is 4950 images processed on the 6919 available.\n",
      "\n",
      "there is 5000 images processed on the 6919 available.\n",
      "\n",
      "there is 5050 images processed on the 6919 available.\n",
      "\n",
      "there is 5100 images processed on the 6919 available.\n",
      "\n",
      "there is 5150 images processed on the 6919 available.\n",
      "\n",
      "there is 5200 images processed on the 6919 available.\n",
      "\n",
      "there is 5250 images processed on the 6919 available.\n",
      "\n",
      "there is 5300 images processed on the 6919 available.\n",
      "\n",
      "there is 5350 images processed on the 6919 available.\n",
      "\n",
      "there is 5400 images processed on the 6919 available.\n",
      "\n",
      "there is 5450 images processed on the 6919 available.\n",
      "\n",
      "there is 5500 images processed on the 6919 available.\n",
      "\n",
      "there is 5550 images processed on the 6919 available.\n",
      "\n",
      "there is 5600 images processed on the 6919 available.\n",
      "\n",
      "there is 5650 images processed on the 6919 available.\n",
      "\n",
      "there is 5700 images processed on the 6919 available.\n",
      "\n",
      "there is 5750 images processed on the 6919 available.\n",
      "\n",
      "there is 5800 images processed on the 6919 available.\n",
      "\n",
      "there is 5850 images processed on the 6919 available.\n",
      "\n",
      "there is 5900 images processed on the 6919 available.\n",
      "\n",
      "there is 5950 images processed on the 6919 available.\n",
      "\n",
      "there is 6000 images processed on the 6919 available.\n",
      "\n",
      "there is 6050 images processed on the 6919 available.\n",
      "\n",
      "there is 6100 images processed on the 6919 available.\n",
      "\n",
      "there is 6150 images processed on the 6919 available.\n",
      "\n",
      "there is 6200 images processed on the 6919 available.\n",
      "\n",
      "there is 6250 images processed on the 6919 available.\n",
      "\n",
      "there is 6300 images processed on the 6919 available.\n",
      "\n",
      "there is 6350 images processed on the 6919 available.\n",
      "\n",
      "there is 6400 images processed on the 6919 available.\n",
      "\n",
      "there is 6450 images processed on the 6919 available.\n",
      "\n",
      "there is 6500 images processed on the 6919 available.\n",
      "\n",
      "there is 6550 images processed on the 6919 available.\n",
      "\n",
      "there is 6600 images processed on the 6919 available.\n",
      "\n",
      "there is 6650 images processed on the 6919 available.\n",
      "\n",
      "there is 6700 images processed on the 6919 available.\n",
      "\n",
      "there is 6750 images processed on the 6919 available.\n",
      "\n",
      "there is 6800 images processed on the 6919 available.\n",
      "\n",
      "there is 6850 images processed on the 6919 available.\n",
      "\n",
      "there is 6900 images processed on the 6919 available.\n",
      "\n",
      "./datasets/carfusion/test/car_penn2/images_jpg\n",
      "there is 0 images processed on the 5842 available.\n",
      "\n",
      "there is 50 images processed on the 5842 available.\n",
      "\n",
      "there is 100 images processed on the 5842 available.\n",
      "\n",
      "there is 150 images processed on the 5842 available.\n",
      "\n",
      "there is 200 images processed on the 5842 available.\n",
      "\n",
      "there is 250 images processed on the 5842 available.\n",
      "\n",
      "there is 300 images processed on the 5842 available.\n",
      "\n",
      "there is 350 images processed on the 5842 available.\n",
      "\n",
      "there is 400 images processed on the 5842 available.\n",
      "\n",
      "there is 450 images processed on the 5842 available.\n",
      "\n",
      "there is 500 images processed on the 5842 available.\n",
      "\n",
      "there is 550 images processed on the 5842 available.\n",
      "\n",
      "there is 600 images processed on the 5842 available.\n",
      "\n",
      "there is 650 images processed on the 5842 available.\n",
      "\n",
      "there is 700 images processed on the 5842 available.\n",
      "\n",
      "there is 750 images processed on the 5842 available.\n",
      "\n",
      "there is 800 images processed on the 5842 available.\n",
      "\n",
      "there is 850 images processed on the 5842 available.\n",
      "\n",
      "there is 900 images processed on the 5842 available.\n",
      "\n",
      "there is 950 images processed on the 5842 available.\n",
      "\n",
      "there is 1000 images processed on the 5842 available.\n",
      "\n",
      "there is 1050 images processed on the 5842 available.\n",
      "\n",
      "there is 1100 images processed on the 5842 available.\n",
      "\n",
      "there is 1150 images processed on the 5842 available.\n",
      "\n",
      "there is 1200 images processed on the 5842 available.\n",
      "\n",
      "there is 1250 images processed on the 5842 available.\n",
      "\n",
      "there is 1300 images processed on the 5842 available.\n",
      "\n",
      "there is 1350 images processed on the 5842 available.\n",
      "\n",
      "there is 1400 images processed on the 5842 available.\n",
      "\n",
      "there is 1450 images processed on the 5842 available.\n",
      "\n",
      "there is 1500 images processed on the 5842 available.\n",
      "\n",
      "there is 1550 images processed on the 5842 available.\n",
      "\n",
      "there is 1600 images processed on the 5842 available.\n",
      "\n",
      "there is 1650 images processed on the 5842 available.\n",
      "\n",
      "there is 1700 images processed on the 5842 available.\n",
      "\n",
      "there is 1750 images processed on the 5842 available.\n",
      "\n",
      "there is 1800 images processed on the 5842 available.\n",
      "\n",
      "there is 1850 images processed on the 5842 available.\n",
      "\n",
      "there is 1900 images processed on the 5842 available.\n",
      "\n",
      "there is 1950 images processed on the 5842 available.\n",
      "\n",
      "there is 2000 images processed on the 5842 available.\n",
      "\n",
      "there is 2050 images processed on the 5842 available.\n",
      "\n",
      "there is 2100 images processed on the 5842 available.\n",
      "\n",
      "there is 2150 images processed on the 5842 available.\n",
      "\n",
      "there is 2200 images processed on the 5842 available.\n",
      "\n",
      "there is 2250 images processed on the 5842 available.\n",
      "\n",
      "there is 2300 images processed on the 5842 available.\n",
      "\n",
      "there is 2350 images processed on the 5842 available.\n",
      "\n",
      "there is 2400 images processed on the 5842 available.\n",
      "\n",
      "there is 2450 images processed on the 5842 available.\n",
      "\n",
      "there is 2500 images processed on the 5842 available.\n",
      "\n",
      "there is 2550 images processed on the 5842 available.\n",
      "\n",
      "there is 2600 images processed on the 5842 available.\n",
      "\n",
      "there is 2650 images processed on the 5842 available.\n",
      "\n",
      "there is 2700 images processed on the 5842 available.\n",
      "\n",
      "there is 2750 images processed on the 5842 available.\n",
      "\n",
      "there is 2800 images processed on the 5842 available.\n",
      "\n",
      "there is 2850 images processed on the 5842 available.\n",
      "\n",
      "there is 2900 images processed on the 5842 available.\n",
      "\n",
      "there is 2950 images processed on the 5842 available.\n",
      "\n",
      "there is 3000 images processed on the 5842 available.\n",
      "\n",
      "there is 3050 images processed on the 5842 available.\n",
      "\n",
      "there is 3100 images processed on the 5842 available.\n",
      "\n",
      "there is 3150 images processed on the 5842 available.\n",
      "\n",
      "there is 3200 images processed on the 5842 available.\n",
      "\n",
      "there is 3250 images processed on the 5842 available.\n",
      "\n",
      "there is 3300 images processed on the 5842 available.\n",
      "\n",
      "there is 3350 images processed on the 5842 available.\n",
      "\n",
      "there is 3400 images processed on the 5842 available.\n",
      "\n",
      "there is 3450 images processed on the 5842 available.\n",
      "\n",
      "there is 3500 images processed on the 5842 available.\n",
      "\n",
      "there is 3550 images processed on the 5842 available.\n",
      "\n",
      "there is 3600 images processed on the 5842 available.\n",
      "\n",
      "there is 3650 images processed on the 5842 available.\n",
      "\n",
      "there is 3700 images processed on the 5842 available.\n",
      "\n",
      "there is 3750 images processed on the 5842 available.\n",
      "\n",
      "there is 3800 images processed on the 5842 available.\n",
      "\n",
      "there is 3850 images processed on the 5842 available.\n",
      "\n",
      "there is 3900 images processed on the 5842 available.\n",
      "\n",
      "there is 3950 images processed on the 5842 available.\n",
      "\n",
      "there is 4000 images processed on the 5842 available.\n",
      "\n",
      "there is 4050 images processed on the 5842 available.\n",
      "\n",
      "there is 4100 images processed on the 5842 available.\n",
      "\n",
      "there is 4150 images processed on the 5842 available.\n",
      "\n",
      "there is 4200 images processed on the 5842 available.\n",
      "\n",
      "there is 4250 images processed on the 5842 available.\n",
      "\n",
      "there is 4300 images processed on the 5842 available.\n",
      "\n",
      "there is 4350 images processed on the 5842 available.\n",
      "\n",
      "there is 4400 images processed on the 5842 available.\n",
      "\n",
      "there is 4450 images processed on the 5842 available.\n",
      "\n",
      "there is 4500 images processed on the 5842 available.\n",
      "\n",
      "there is 4550 images processed on the 5842 available.\n",
      "\n",
      "there is 4600 images processed on the 5842 available.\n",
      "\n",
      "there is 4650 images processed on the 5842 available.\n",
      "\n",
      "there is 4700 images processed on the 5842 available.\n",
      "\n",
      "there is 4750 images processed on the 5842 available.\n",
      "\n",
      "there is 4800 images processed on the 5842 available.\n",
      "\n",
      "there is 4850 images processed on the 5842 available.\n",
      "\n",
      "there is 4900 images processed on the 5842 available.\n",
      "\n",
      "there is 4950 images processed on the 5842 available.\n",
      "\n",
      "there is 5000 images processed on the 5842 available.\n",
      "\n",
      "there is 5050 images processed on the 5842 available.\n",
      "\n",
      "there is 5100 images processed on the 5842 available.\n",
      "\n",
      "there is 5150 images processed on the 5842 available.\n",
      "\n",
      "there is 5200 images processed on the 5842 available.\n",
      "\n",
      "there is 5250 images processed on the 5842 available.\n",
      "\n",
      "there is 5300 images processed on the 5842 available.\n",
      "\n",
      "there is 5350 images processed on the 5842 available.\n",
      "\n",
      "there is 5400 images processed on the 5842 available.\n",
      "\n",
      "there is 5450 images processed on the 5842 available.\n",
      "\n",
      "there is 5500 images processed on the 5842 available.\n",
      "\n",
      "there is 5550 images processed on the 5842 available.\n",
      "\n",
      "there is 5600 images processed on the 5842 available.\n",
      "\n",
      "there is 5650 images processed on the 5842 available.\n",
      "\n",
      "there is 5700 images processed on the 5842 available.\n",
      "\n",
      "there is 5750 images processed on the 5842 available.\n",
      "\n",
      "there is 5800 images processed on the 5842 available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sub_dir in os.listdir(image_dir):\n",
    "    im_size = True\n",
    "    \n",
    "    if sub_dir[:3] == 'car' and \".zip\" not in sub_dir:\n",
    "        loop= loop+1\n",
    "        im_dir = os.path.join(image_dir,sub_dir)+'/images_jpg'\n",
    "\n",
    "        labels_dir = os.path.join(image_dir,sub_dir) + '/gt/'\n",
    "        print(im_dir)\n",
    "        for i,file_name in enumerate(os.listdir(labels_dir)):\n",
    "\n",
    "            if i%50 == 0:\n",
    "                print(f\"there is {i} images processed on the {len(os.listdir(labels_dir))} available.\\n\")\n",
    "                \n",
    "            if(file_name[-3:]!='txt'):\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            count_images =count_images+1\n",
    "            file_str = file_name.split('.')[0]\n",
    "            vid_str, id_str  = file_str.split('_')\n",
    "\n",
    "            # Get the ID of the images\n",
    "            frame_id = int(id_str)\n",
    "            video_id = int(vid_str)\n",
    "            image_id = int(loop*1e8+video_id*1e5+frame_id)\n",
    "\n",
    "            image_name = os.path.join(im_dir, \"{}.jpg\".format(file_str))\n",
    "\n",
    "            \n",
    "            if im_size: # Get the size of the images\n",
    "                im_size = False\n",
    "                im = Image.open(image_name)\n",
    "                width, height = im.size\n",
    "                \n",
    "            data[\"images\"].append({\n",
    "                'coco_url': \"unknown\",\n",
    "                'file_name': image_name,\n",
    "                'id': image_id,\n",
    "                'license':1,\n",
    "                #'has_visible_keypoints':True,\n",
    "                'date_captured': \"unknown\",\n",
    "                'width': width,\n",
    "                'height': height})\n",
    "\n",
    "\n",
    "            with open(os.path.join(labels_dir, file_name.split('.')[0]+'.txt')) as f:\n",
    "                keypoints = f.readlines()\n",
    "                keypoints = [s.split(',') for s in keypoints]\n",
    "                keypoints = [list(map(num, s)) for s in keypoints]\n",
    "                \n",
    "            #detect the cars in the image\n",
    "            detections = detector.detectCustomObjectsFromImage( custom_objects=custom, input_image =image_name, output_image_path=out, minimum_percentage_probability=30)\n",
    "            boxes_imageAI = []\n",
    "            for obj in detections:\n",
    "                # Create a Rectangle patch\n",
    "                box = obj[\"box_points\"]\n",
    "                boxes_imageAI.append([box[0], box[1], box[2]-box[0], box[3]-box[1]])\n",
    "            \n",
    "            instances = {}\n",
    "            \n",
    "            assert len(keypoints)!=0\n",
    "            \n",
    "            for keypoint in keypoints:\n",
    "                if keypoint[3] not in instances: #check if keypoint is in the list\n",
    "                    instances[keypoint[3]] = np.zeros((number_keypoints, 3), dtype=np.int32) \n",
    "                instances[keypoint[3]][keypoint[2]-1,0] = keypoint[0] # X coordinate \n",
    "                instances[keypoint[3]][keypoint[2]-1,1] = keypoint[1] # Y Coordinate\n",
    "                if keypoint[4] == 2:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 1\n",
    "                elif keypoint[4] == 1 or keypoint[4] == 3:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 2\n",
    "\n",
    "                if keypoint[0] <= 0 or keypoint[1] > height or keypoint[1] <= 0 or keypoint[0] > width:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 0  #Identify the keypoints outside of the frame of the image            \n",
    "                \n",
    "            ## Keypoints detected on the cars       \n",
    "            for instance in instances.values():\n",
    "                \n",
    "                bbox, segmentation, keypoints, num_keypoints = getAnnotation(instance, number_keypoints, width, height)\n",
    "                \n",
    "                if num_keypoints > keypoints_threshold:\n",
    "                    \n",
    "                    #print(len(boxes_imageAI))\n",
    "                    for box in boxes_imageAI:\n",
    "                        if(compute_IOU(bbox,box) > iou_threshold):\n",
    "                            \n",
    "                            boxes_imageAI.remove(box)                    \n",
    "                    \n",
    "                    data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': num_keypoints,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1\n",
    "            \n",
    "             ## Bounding boxes for the car\n",
    "            for box in boxes_imageAI:\n",
    "                \n",
    "                keypoints = [0 for a in range(number_keypoints*3)]\n",
    "                hull = Polygon([(box[0],box[1]),(box[0] + box[2], box[1]),\n",
    "                                (box[0],box[1] + box[3]),(box[0] + box[2],box[1] + box[3])]).convex_hull\n",
    "                frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "                hull = hull.intersection(frame).convex_hull\n",
    "                bbox = hull.bounds\n",
    "                w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "                x_o = max(bbox[0]-(w/10),0)\n",
    "                y_o = max(bbox[1]-(h/10),0)\n",
    "                x_i = min(x_o+(w/4)+w,width)\n",
    "                y_i = min(y_o+(h/4)+h,height)\n",
    "                bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "                \n",
    "                seg = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "                seg = [[int(x[0]), int(x[1])] for x in seg]\n",
    "                segmentation = []\n",
    "\n",
    "                for s in seg:\n",
    "                    segmentation.append(s[0])\n",
    "                    segmentation.append(s[1])\n",
    "                \n",
    "                \n",
    "                data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': 0,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_test0.3.json 12761\n"
     ]
    }
   ],
   "source": [
    "json_str = json.dumps(data)\n",
    "\n",
    "print(json_name,count_images)\n",
    "ann_file = os.path.join(output_dir, json_name)\n",
    "if not os.path.exists(output_dir):\n",
    "     os.mkdir(output_dir)\n",
    "with open(ann_file, 'w') as f:\n",
    "     f.write(json_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if car_only :\n",
    "    output_filename = 'car_only_'+ data_type+text\n",
    "else :\n",
    "    output_filename = 'car_'+ data_type+text\n",
    "\n",
    "if data_type=='train':\n",
    "    image_dir = os.path.join(dir_carfusion,\"train\")\n",
    "else:\n",
    "    image_dir = os.path.join(dir_carfusion,\"test\")\n",
    "    \n",
    "\n",
    "output_dir = os.getcwd()+\"/annotations\"\n",
    "path_dir = dir_carfusion\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "data[\"info\"] = {\n",
    "        'url': \"https://www.epfl.ch/labs/vita/\",\n",
    "        'year': time.localtime().tm_year,\n",
    "        'date_created': time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\",\n",
    "            time.localtime()),\n",
    "        'description': \"This is a keypoint dataset for object detection.\",\n",
    "        'version': '1.0',\n",
    "        'contributor': 'VITA laboratory'}\n",
    "\n",
    "data[\"categories\"] = [{'name': 'car',\n",
    "    'id': 1,\n",
    "    'skeleton':skeleton,\n",
    "                       \n",
    "    'supercategory': 'car',\n",
    "    'keypoints': [str(x) for x in range(14)]}]\n",
    "\n",
    "data[\"licenses\"] = [{'id': 1,\n",
    "            'name': \"unknown\",\n",
    "            'url': \"unknown\"}]\n",
    "\n",
    "\n",
    "obj_id = 0\n",
    "# expect sub-folder for subsets\n",
    "data[\"images\"] = []\n",
    "data[\"annotations\"] = []\n",
    "json_name = output_filename+'.json'\n",
    "loop=0\n",
    "count_images=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/carfusion/train/car_craig1/images_jpg\n",
      "there is 0 images processed on the 3674 available.\n",
      "\n",
      "there is 50 images processed on the 3674 available.\n",
      "\n",
      "there is 100 images processed on the 3674 available.\n",
      "\n",
      "there is 150 images processed on the 3674 available.\n",
      "\n",
      "there is 200 images processed on the 3674 available.\n",
      "\n",
      "there is 250 images processed on the 3674 available.\n",
      "\n",
      "there is 300 images processed on the 3674 available.\n",
      "\n",
      "there is 350 images processed on the 3674 available.\n",
      "\n",
      "there is 400 images processed on the 3674 available.\n",
      "\n",
      "there is 450 images processed on the 3674 available.\n",
      "\n",
      "there is 500 images processed on the 3674 available.\n",
      "\n",
      "there is 550 images processed on the 3674 available.\n",
      "\n",
      "there is 600 images processed on the 3674 available.\n",
      "\n",
      "there is 650 images processed on the 3674 available.\n",
      "\n",
      "there is 700 images processed on the 3674 available.\n",
      "\n",
      "there is 750 images processed on the 3674 available.\n",
      "\n",
      "there is 800 images processed on the 3674 available.\n",
      "\n",
      "there is 850 images processed on the 3674 available.\n",
      "\n",
      "there is 900 images processed on the 3674 available.\n",
      "\n",
      "there is 950 images processed on the 3674 available.\n",
      "\n",
      "there is 1000 images processed on the 3674 available.\n",
      "\n",
      "there is 1050 images processed on the 3674 available.\n",
      "\n",
      "there is 1100 images processed on the 3674 available.\n",
      "\n",
      "there is 1150 images processed on the 3674 available.\n",
      "\n",
      "there is 1200 images processed on the 3674 available.\n",
      "\n",
      "there is 1250 images processed on the 3674 available.\n",
      "\n",
      "there is 1300 images processed on the 3674 available.\n",
      "\n",
      "there is 1350 images processed on the 3674 available.\n",
      "\n",
      "there is 1400 images processed on the 3674 available.\n",
      "\n",
      "there is 1450 images processed on the 3674 available.\n",
      "\n",
      "there is 1500 images processed on the 3674 available.\n",
      "\n",
      "there is 1550 images processed on the 3674 available.\n",
      "\n",
      "there is 1600 images processed on the 3674 available.\n",
      "\n",
      "there is 1650 images processed on the 3674 available.\n",
      "\n",
      "there is 1700 images processed on the 3674 available.\n",
      "\n",
      "there is 1750 images processed on the 3674 available.\n",
      "\n",
      "there is 1800 images processed on the 3674 available.\n",
      "\n",
      "there is 1850 images processed on the 3674 available.\n",
      "\n",
      "there is 1900 images processed on the 3674 available.\n",
      "\n",
      "there is 1950 images processed on the 3674 available.\n",
      "\n",
      "there is 2000 images processed on the 3674 available.\n",
      "\n",
      "there is 2050 images processed on the 3674 available.\n",
      "\n",
      "there is 2100 images processed on the 3674 available.\n",
      "\n",
      "there is 2150 images processed on the 3674 available.\n",
      "\n",
      "there is 2200 images processed on the 3674 available.\n",
      "\n",
      "there is 2250 images processed on the 3674 available.\n",
      "\n",
      "there is 2300 images processed on the 3674 available.\n",
      "\n",
      "there is 2350 images processed on the 3674 available.\n",
      "\n",
      "there is 2400 images processed on the 3674 available.\n",
      "\n",
      "there is 2450 images processed on the 3674 available.\n",
      "\n",
      "there is 2500 images processed on the 3674 available.\n",
      "\n",
      "there is 2550 images processed on the 3674 available.\n",
      "\n",
      "there is 2600 images processed on the 3674 available.\n",
      "\n",
      "there is 2650 images processed on the 3674 available.\n",
      "\n",
      "there is 2700 images processed on the 3674 available.\n",
      "\n",
      "there is 2750 images processed on the 3674 available.\n",
      "\n",
      "there is 2800 images processed on the 3674 available.\n",
      "\n",
      "there is 2850 images processed on the 3674 available.\n",
      "\n",
      "there is 2900 images processed on the 3674 available.\n",
      "\n",
      "there is 2950 images processed on the 3674 available.\n",
      "\n",
      "there is 3000 images processed on the 3674 available.\n",
      "\n",
      "there is 3050 images processed on the 3674 available.\n",
      "\n",
      "there is 3100 images processed on the 3674 available.\n",
      "\n",
      "there is 3150 images processed on the 3674 available.\n",
      "\n",
      "there is 3200 images processed on the 3674 available.\n",
      "\n",
      "there is 3250 images processed on the 3674 available.\n",
      "\n",
      "there is 3300 images processed on the 3674 available.\n",
      "\n",
      "there is 3350 images processed on the 3674 available.\n",
      "\n",
      "there is 3400 images processed on the 3674 available.\n",
      "\n",
      "there is 3450 images processed on the 3674 available.\n",
      "\n",
      "there is 3500 images processed on the 3674 available.\n",
      "\n",
      "there is 3550 images processed on the 3674 available.\n",
      "\n",
      "there is 3600 images processed on the 3674 available.\n",
      "\n",
      "there is 3650 images processed on the 3674 available.\n",
      "\n",
      "./datasets/carfusion/train/car_craig2/images_jpg\n",
      "there is 0 images processed on the 3474 available.\n",
      "\n",
      "there is 50 images processed on the 3474 available.\n",
      "\n",
      "there is 100 images processed on the 3474 available.\n",
      "\n",
      "there is 150 images processed on the 3474 available.\n",
      "\n",
      "there is 200 images processed on the 3474 available.\n",
      "\n",
      "there is 250 images processed on the 3474 available.\n",
      "\n",
      "there is 300 images processed on the 3474 available.\n",
      "\n",
      "there is 350 images processed on the 3474 available.\n",
      "\n",
      "there is 400 images processed on the 3474 available.\n",
      "\n",
      "there is 450 images processed on the 3474 available.\n",
      "\n",
      "there is 500 images processed on the 3474 available.\n",
      "\n",
      "there is 550 images processed on the 3474 available.\n",
      "\n",
      "there is 600 images processed on the 3474 available.\n",
      "\n",
      "there is 650 images processed on the 3474 available.\n",
      "\n",
      "there is 700 images processed on the 3474 available.\n",
      "\n",
      "there is 750 images processed on the 3474 available.\n",
      "\n",
      "there is 800 images processed on the 3474 available.\n",
      "\n",
      "there is 850 images processed on the 3474 available.\n",
      "\n",
      "there is 900 images processed on the 3474 available.\n",
      "\n",
      "there is 950 images processed on the 3474 available.\n",
      "\n",
      "there is 1000 images processed on the 3474 available.\n",
      "\n",
      "there is 1050 images processed on the 3474 available.\n",
      "\n",
      "there is 1100 images processed on the 3474 available.\n",
      "\n",
      "there is 1150 images processed on the 3474 available.\n",
      "\n",
      "there is 1200 images processed on the 3474 available.\n",
      "\n",
      "there is 1250 images processed on the 3474 available.\n",
      "\n",
      "there is 1300 images processed on the 3474 available.\n",
      "\n",
      "there is 1350 images processed on the 3474 available.\n",
      "\n",
      "there is 1400 images processed on the 3474 available.\n",
      "\n",
      "there is 1450 images processed on the 3474 available.\n",
      "\n",
      "there is 1500 images processed on the 3474 available.\n",
      "\n",
      "there is 1550 images processed on the 3474 available.\n",
      "\n",
      "there is 1600 images processed on the 3474 available.\n",
      "\n",
      "there is 1650 images processed on the 3474 available.\n",
      "\n",
      "there is 1700 images processed on the 3474 available.\n",
      "\n",
      "there is 1750 images processed on the 3474 available.\n",
      "\n",
      "there is 1800 images processed on the 3474 available.\n",
      "\n",
      "there is 1850 images processed on the 3474 available.\n",
      "\n",
      "there is 1900 images processed on the 3474 available.\n",
      "\n",
      "there is 1950 images processed on the 3474 available.\n",
      "\n",
      "there is 2000 images processed on the 3474 available.\n",
      "\n",
      "there is 2050 images processed on the 3474 available.\n",
      "\n",
      "there is 2100 images processed on the 3474 available.\n",
      "\n",
      "there is 2150 images processed on the 3474 available.\n",
      "\n",
      "there is 2200 images processed on the 3474 available.\n",
      "\n",
      "there is 2250 images processed on the 3474 available.\n",
      "\n",
      "there is 2300 images processed on the 3474 available.\n",
      "\n",
      "there is 2350 images processed on the 3474 available.\n",
      "\n",
      "there is 2400 images processed on the 3474 available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sub_dir in os.listdir(image_dir):\n",
    "    im_size = True\n",
    "    \n",
    "    if sub_dir[:3] == 'car' and \".zip\" not in sub_dir:\n",
    "        loop= loop+1\n",
    "        im_dir = os.path.join(image_dir,sub_dir)+'/images_jpg'\n",
    "\n",
    "        labels_dir = os.path.join(image_dir,sub_dir) + '/gt/'\n",
    "        print(im_dir)\n",
    "        for i,file_name in enumerate(os.listdir(labels_dir)):\n",
    "\n",
    "            if i%50 == 0:\n",
    "                print(f\"there is {i} images processed on the {len(os.listdir(labels_dir))} available.\\n\")\n",
    "                \n",
    "            if(file_name[-3:]!='txt'):\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            count_images =count_images+1\n",
    "            file_str = file_name.split('.')[0]\n",
    "            vid_str, id_str  = file_str.split('_')\n",
    "\n",
    "            # Get the ID of the images\n",
    "            frame_id = int(id_str)\n",
    "            video_id = int(vid_str)\n",
    "            image_id = int(loop*1e8+video_id*1e5+frame_id)\n",
    "\n",
    "            image_name = os.path.join(im_dir, \"{}.jpg\".format(file_str))\n",
    "\n",
    "            \n",
    "            if im_size: # Get the size of the images\n",
    "                im_size = False\n",
    "                im = Image.open(image_name)\n",
    "                width, height = im.size\n",
    "                \n",
    "            data[\"images\"].append({\n",
    "                'coco_url': \"unknown\",\n",
    "                'file_name': image_name,\n",
    "                'id': image_id,\n",
    "                'license':1,\n",
    "                #'has_visible_keypoints':True,\n",
    "                'date_captured': \"unknown\",\n",
    "                'width': width,\n",
    "                'height': height})\n",
    "\n",
    "\n",
    "            with open(os.path.join(labels_dir, file_name.split('.')[0]+'.txt')) as f:\n",
    "                keypoints = f.readlines()\n",
    "                keypoints = [s.split(',') for s in keypoints]\n",
    "                keypoints = [list(map(num, s)) for s in keypoints]\n",
    "                \n",
    "            #detect the cars in the image\n",
    "            detections = detector.detectCustomObjectsFromImage( custom_objects=custom, input_image =image_name, output_image_path=out, minimum_percentage_probability=30)\n",
    "            boxes_imageAI = []\n",
    "            for obj in detections:\n",
    "                # Create a Rectangle patch\n",
    "                box = obj[\"box_points\"]\n",
    "                boxes_imageAI.append([box[0], box[1], box[2]-box[0], box[3]-box[1]])\n",
    "            \n",
    "            instances = {}\n",
    "            \n",
    "            assert len(keypoints)!=0\n",
    "            \n",
    "            for keypoint in keypoints:\n",
    "                if keypoint[3] not in instances: #check if keypoint is in the list\n",
    "                    instances[keypoint[3]] = np.zeros((number_keypoints, 3), dtype=np.int32) \n",
    "                instances[keypoint[3]][keypoint[2]-1,0] = keypoint[0] # X coordinate \n",
    "                instances[keypoint[3]][keypoint[2]-1,1] = keypoint[1] # Y Coordinate\n",
    "                if keypoint[4] == 2:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 1\n",
    "                elif keypoint[4] == 1 or keypoint[4] == 3:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 2\n",
    "\n",
    "                if keypoint[0] <= 0 or keypoint[1] > height or keypoint[1] <= 0 or keypoint[0] > width:\n",
    "                    instances[keypoint[3]][keypoint[2]-1,2] = 0  #Identify the keypoints outside of the frame of the image            \n",
    "                \n",
    "            ## Keypoints detected on the cars       \n",
    "            for instance in instances.values():\n",
    "                \n",
    "                bbox, segmentation, keypoints, num_keypoints = getAnnotation(instance, number_keypoints, width, height)\n",
    "                \n",
    "                if num_keypoints > keypoints_threshold:\n",
    "                    \n",
    "                    #print(len(boxes_imageAI))\n",
    "                    for box in boxes_imageAI:\n",
    "                        if(compute_IOU(bbox,box) > iou_threshold):\n",
    "                            \n",
    "                            boxes_imageAI.remove(box)                    \n",
    "                    \n",
    "                    data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': num_keypoints,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1\n",
    "            \n",
    "             ## Bounding boxes for the car\n",
    "            for box in boxes_imageAI:\n",
    "                \n",
    "                keypoints = [0 for a in range(number_keypoints*3)]\n",
    "                hull = Polygon([(box[0],box[1]),(box[0] + box[2], box[1]),\n",
    "                                (box[0],box[1] + box[3]),(box[0] + box[2],box[1] + box[3])]).convex_hull\n",
    "                frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "                hull = hull.intersection(frame).convex_hull\n",
    "                bbox = hull.bounds\n",
    "                w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "                x_o = max(bbox[0]-(w/10),0)\n",
    "                y_o = max(bbox[1]-(h/10),0)\n",
    "                x_i = min(x_o+(w/4)+w,width)\n",
    "                y_i = min(y_o+(h/4)+h,height)\n",
    "                bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "                \n",
    "                seg = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "                seg = [[int(x[0]), int(x[1])] for x in seg]\n",
    "                segmentation = []\n",
    "\n",
    "                for s in seg:\n",
    "                    segmentation.append(s[0])\n",
    "                    segmentation.append(s[1])\n",
    "                \n",
    "                \n",
    "                data[\"annotations\"].append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': 1,\n",
    "                        'iscrowd': 0,\n",
    "                        #'has_visible_keypoints': True,\n",
    "                        'id': obj_id,\n",
    "                        'area': bbox[2]*bbox[3],\n",
    "                        'bbox': bbox,\n",
    "                        'num_keypoints': 0,\n",
    "                        'keypoints': keypoints[:span0*3] + keypoints[span1*3:], # We can remove some keypoints that we deem not necessary here.\n",
    "                        'segmentation': [segmentation]})\n",
    "                \n",
    "                obj_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(data)\n",
    "\n",
    "print(json_name,count_images)\n",
    "ann_file = os.path.join(output_dir, json_name)\n",
    "if not os.path.exists(output_dir):\n",
    "     os.mkdir(output_dir)\n",
    "with open(ann_file, 'w') as f:\n",
    "     f.write(json_str)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "#from IPython import embed\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def num(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return int(float(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sytem initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to define there the type of data that you want to fetch, the number of keypoints, hresholds, etc ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_category = \"vehicle\" #in the coco formatting, the supercategory for the cars is \"vehicle\"\n",
    "number_keypoints = 14 #Number of keypoints of the cars\n",
    "threshold = 1 # minimum number of keypoints to consider the cars in both the training and validation dataset\n",
    "\n",
    "\n",
    "train_test_ratio = 1.0 #ratio between the training + validation and testing \n",
    "train_val_ratio = 0.7 #Ratio between training and validation\n",
    "\n",
    "COCO_KEYPOINTS = [\n",
    "\n",
    "    'front_left_wheel',         #1          0\n",
    "    'front_right_wheel',        #2          1\n",
    "    'back_left_wheel',          #3          2\n",
    "    'back_right_wheel',         #4          3\n",
    "    'front_left_light',         #5          4\n",
    "    'front_right_light',        #6          5\n",
    "    'back_left_light',          #7          6\n",
    "    'back_right_light',         #8          7\n",
    "    'left_mirror',              #9          8\n",
    "    'right_mirror',             #10         9\n",
    "    'upper_left_windshield',    #11         10\n",
    "    'upper_right_windshield',   #12         11\n",
    "    'upper_left_rear',          #13         12\n",
    "    'upper_right_rear',         #14         13\n",
    "]\n",
    "\n",
    "SKELETON = [\n",
    "            [1, 2], [1,3], [2,4], [3,4],    #wheels\n",
    "            [1,5], [2,6],[3,7], [4,8],      #Links between the wheels and the lights\n",
    "            [5,6], [7,8],                   #links between the lights\n",
    "            [5,9], [6,10],                  #links between the mirrors and the front lights\n",
    "            [5,11],[6,12], [7,13],[8,14],   #links between the lights and the windshiel/rear\n",
    "            [11,12],[11,13],[12,14],[13,14] #links between the rear and the windshiel ,\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs and inputs of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_dir = \"/data/bonnesoeur-data/data/samsung/scenes\"           # The folder where the scenes files are contained\n",
    "\n",
    "annotations_dir= \"/data/bonnesoeur-data/data/samsung/json_samsung\" # The folder containing the json for those scenes\n",
    "\n",
    "output_dir = os.getcwd()+\"/results_coco\"                           # The output directory where the json files will be saved\n",
    "\n",
    "jsons = ['car_train.json', 'car_val.json', 'car_test.json']       \n",
    "        # Name of the json files with the annotations for training, velidation and testing\n",
    "\n",
    "jsons_paths = [output_dir+'/'+json for json in jsons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box and keypoint converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function just arrange the data in a coco style format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnnotation(instance, total_keypoints ,width, height):\n",
    "\n",
    "    visible = instance[:,2]>0\n",
    "    num_keypoints = int(np.sum(visible))\n",
    "\n",
    "    keypoints = np.zeros((total_keypoints,3), dtype=np.int32)\n",
    "    try:\n",
    "        hull = Polygon([(x[0], x[1]) for x in instance[visible, :2]]).convex_hull\n",
    "        frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "        hull = hull.intersection(frame).convex_hull\n",
    "\n",
    "        bbox = hull.bounds\n",
    "        w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "        x_o = max(bbox[0]-(w/10),0)\n",
    "        y_o = max(bbox[1]-(h/10),0)\n",
    "        x_i = min(x_o+(w/4)+w,width)\n",
    "        y_i = min(y_o+(h/4)+h,height)\n",
    "        bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "\n",
    "        segmentation = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "        segmentation = [[int(x[0]), int(x[1])] for x in segmentation]\n",
    "\n",
    "        keypoints[:, :] = instance[:, :]\n",
    "\n",
    "    except:\n",
    "        bbox = [0, 0, 0, 0]\n",
    "        segmentation = []\n",
    "\n",
    "    keypoints = np.reshape(keypoints, (total_keypoints*3,))\n",
    "    keypoints = keypoints.tolist()\n",
    "    keypoints = [int(x) for x in keypoints]\n",
    "\n",
    "    seg = []\n",
    "    for s in segmentation:\n",
    "        seg.append(s[0])\n",
    "        seg.append(s[1])\n",
    "\n",
    "\n",
    "    return bbox, seg, keypoints, num_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_saver(data, json_path,count_scenes, output_dir):\n",
    "    #Save the processed data\n",
    "    \n",
    "    \n",
    "    json_str = json.dumps(data)\n",
    "    print(json_path,count_scenes)\n",
    "    ann_file = json_path\n",
    "    if not os.path.exists(output_dir):\n",
    "         os.mkdir(output_dir)\n",
    "    with open(ann_file, 'w') as f:\n",
    "         f.write(json_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init():\n",
    "    \n",
    "    #Initialize the data structure\n",
    "    my_data = {}\n",
    "\n",
    "    my_data[\"info\"] = {\n",
    "            'url': \"https://www.epfl.ch/labs/vita/\",\n",
    "            'year': time.localtime().tm_year,\n",
    "            'date_created': time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\",\n",
    "                time.localtime()),\n",
    "            'description': \"This is a keypoint dataset for object detection.\",\n",
    "            'version': '1.0',\n",
    "            'contributor': 'VITA laboratory'}\n",
    "\n",
    "    my_data[\"categories\"] = [{'name': 'car',\n",
    "        'id': 1,\n",
    "        'skeleton': SKELETON,\n",
    "        'supercategory': 'car',\n",
    "        'keypoints': [str(x) for x in range(number_keypoints)]}]\n",
    "\n",
    "    my_data[\"licenses\"] = [{'id': 1,\n",
    "                'name': \"unknown\",\n",
    "                'url': \"unknown\"}]\n",
    "\n",
    "\n",
    "    # expect sub-folder for subsets\n",
    "    my_data[\"images\"] = []\n",
    "    my_data[\"annotations\"] = []\n",
    "    \n",
    "    return my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processor(images_dir, labels_dir, output_dir, json_path, separations):\n",
    "    \n",
    "    #Processing of the images\n",
    "    \n",
    "    obj_id = 0\n",
    "    image_id = 0\n",
    "    image_dico = {}\n",
    "\n",
    "    count_json = 0\n",
    "    count_scenes = 0\n",
    "    \n",
    "    my_data = data_init()\n",
    "\n",
    "    for image_dir in os.listdir(images_dir)[separations[0]:separations[1]]:\n",
    "\n",
    "        count_scenes+=1\n",
    "        im_size = True\n",
    "\n",
    "        json_file = [s for s in os.listdir(labels_dir) if image_dir in s]\n",
    "\n",
    "        if len(json_file)!=0:\n",
    "\n",
    "            count_json+=1\n",
    "\n",
    "            with open(os.path.join(labels_dir,json_file[0])) as json_data:\n",
    "                data = json.load(json_data)\n",
    "\n",
    "\n",
    "            #search for the vehicle category\n",
    "            cat_ids = []\n",
    "            for cat in data[\"categories\"]:\n",
    "                if(cat[\"super_category\"]==super_category):\n",
    "                    cat_ids.append(cat[\"cat_id\"])\n",
    "\n",
    "\n",
    "            #get the size of the images\n",
    "            if im_size:\n",
    "                im = os.path.join(images_dir,image_dir)\n",
    "                im= os.path.join(im,os.listdir(im)[0])\n",
    "                im_size = False\n",
    "                im = Image.open(im)\n",
    "                width, height = im.size\n",
    "\n",
    "            #cycle through the annotations\n",
    "            for annotation in data[\"annotations\"]:\n",
    "\n",
    "                #To prevent an error in the json\n",
    "                if \"cat_id\" not in annotation.keys():\n",
    "                    continue\n",
    "\n",
    "                if annotation[\"cat_id\"] in cat_ids:\n",
    "                    for projection in annotation[\"projections\"]:\n",
    "\n",
    "                        frame_id = annotation[\"pair_id\"]\n",
    "                        time_stamp = data[\"frames\"][frame_id-1][\"point_cloud\"][-27:-10]#data[\"frames\"][frame_id-1][\"time_stamp\"]\n",
    "                        image_name = os.path.join(os.path.join(images_dir,image_dir), time_stamp+\"_\"+projection[\"sensor_id\"]+\"_R.jpg\")\n",
    "                        num_keypoints = 0\n",
    "\n",
    "                        if \"keypoints\" in projection.keys() and len(projection[\"keypoints\"]) != 0 :\n",
    "\n",
    "                            instance = np.zeros((number_keypoints, 3), dtype=np.int32)\n",
    "\n",
    "                            for i, part_type in enumerate(COCO_KEYPOINTS):\n",
    "                                keypoint = projection[\"keypoints\"][part_type]\n",
    "                                instance[i,0] = keypoint[0] # X coordinate \n",
    "                                instance[i,1] = keypoint[1] # Y Coordinate\n",
    "                                instance[i,2] = keypoint[2] # Visible point\n",
    "\n",
    "                                if keypoint[0] <= 0 or keypoint[1] > height or keypoint[1] <= 0 or keypoint[0] > width:\n",
    "                                    instance[i,2] = 0  #Identify the keypoints outside of the frame of the image            \n",
    "\n",
    "                            bbox, segmentation, keypoints, num_keypoints = getAnnotation(instance, number_keypoints, width, height)\n",
    "\n",
    "                            if num_keypoints<threshold:\n",
    "                                num_keypoints = 0\n",
    "\n",
    "                        # Add the cars that do not have enough or any keypoint (categorize them by their bounding box)\n",
    "                        if(num_keypoints == 0):\n",
    "                            keypoints = [0 for a in range(number_keypoints*3)]\n",
    "                            box = projection['bbox']\n",
    "                            hull = Polygon([(box[\"x\"]-1/2*box[\"w\"],box[\"y\"]-1/2*box[\"h\"]),(box[\"x\"] + 1/2*box[\"w\"], box[\"y\"]-1/2*box[\"h\"]),\n",
    "                                            (box[\"x\"]+1/2*box[\"w\"],box[\"y\"] + 1/2*box[\"h\"]),(box[\"x\"]-1/2*box[\"w\"],box[\"y\"] + 1/2*box[\"h\"])]).convex_hull\n",
    "\n",
    "                            frame = Polygon([(0, 0), (width, 0), (width, height), (0, height)])\n",
    "                            hull = hull.intersection(frame).convex_hull\n",
    "                            bbox = hull.bounds\n",
    "                            w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "                            x_o = max(bbox[0]-(w/10),0)\n",
    "                            y_o = max(bbox[1]-(h/10),0)\n",
    "                            x_i = min(x_o+(w/4)+w,width)\n",
    "                            y_i = min(y_o+(h/4)+h,height)\n",
    "                            bbox = [int(x_o), int(y_o), int(x_i - x_o), int(y_i - y_o)]\n",
    "                            #bbox=[box[\"x\"],box[\"y\"],box[\"w\"], box[\"h\"]]\n",
    "\n",
    "\n",
    "                            seg = list(hull.convex_hull.exterior.coords)[:-1]\n",
    "                            seg = [[int(x[0]), int(x[1])] for x in seg]\n",
    "                            segmentation = []\n",
    "\n",
    "                            for s in seg:\n",
    "                                segmentation.append(s[0])\n",
    "                                segmentation.append(s[1])\n",
    "\n",
    "\n",
    "                        #Check if the image is already in the list\n",
    "                        if image_name not in image_dico.keys():\n",
    "                            image_dico[image_name] = image_id\n",
    "                            image_id+=1\n",
    "\n",
    "\n",
    "                            my_data[\"images\"].append({#'flickr_url': \"unknown\",\n",
    "                                'coco_url': data[\"frames\"][annotation[\"pair_id\"]-1][\"point_cloud\"],\n",
    "                                'file_name': image_name,\n",
    "                                'id': image_dico[image_name],\n",
    "                                'license':1,\n",
    "                                'date_captured': \"unknown\",\n",
    "                                'width': width,\n",
    "                                'height': height})\n",
    "\n",
    "                        if (projection[\"difficulty\"] is None):\n",
    "                            crowd = 0\n",
    "                        else :\n",
    "                            crowd = projection[\"difficulty\"]\n",
    "\n",
    "\n",
    "                        my_data[\"annotations\"].append({\n",
    "                            'image_id': image_dico[image_name],\n",
    "                            'category_id': 1,\n",
    "                            'iscrowd': crowd,\n",
    "                            'id': obj_id,\n",
    "                            'area': bbox[2]*bbox[3],\n",
    "                            'bbox': bbox,\n",
    "                            'iscrowd': 0,\n",
    "                            'num_keypoints': num_keypoints,\n",
    "                            'keypoints': keypoints,\n",
    "                            'segmentation': [segmentation]})\n",
    "\n",
    "                        obj_id+=1\n",
    "\n",
    "\n",
    "    print(f\"The total nuber of annotated images is: {image_id} \")\n",
    "    print(f\"The total nuber of annotation is: {obj_id} \")\n",
    "\n",
    "    json_saver(my_data, json_path,count_scenes, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this to process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total nuber of annotated images is: 2622 \n",
      "The total nuber of annotation is: 12408 \n",
      "/home/bonnesoe/semester_project/samsung_to_coco/results_coco/car_train.json 14\n",
      "The total nuber of annotated images is: 895 \n",
      "The total nuber of annotation is: 5565 \n",
      "/home/bonnesoe/semester_project/samsung_to_coco/results_coco/car_val.json 6\n",
      "The total nuber of annotated images is: 0 \n",
      "The total nuber of annotation is: 0 \n",
      "/home/bonnesoe/semester_project/samsung_to_coco/results_coco/car_test.json 0\n"
     ]
    }
   ],
   "source": [
    "number_scenes = len(os.listdir(scenes_dir))\n",
    "separations = [0, train_val_ratio*train_test_ratio, train_test_ratio, 1.0]\n",
    "separation = list(map(int,[separation*number_scenes for separation in separations]))\n",
    "\n",
    "\n",
    "for i, json_path in enumerate(jsons_paths) :\n",
    "    data_processor(scenes_dir,annotations_dir,output_dir, json_path , [separation[i],separation[i+1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
